{"cells":[{"cell_type":"markdown","metadata":{"id":"afs1LvnuFcV6"},"source":["# Transfer Learning\n","\n","**Transfer Learning:**\n","\n","A research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. \n","\n","Can leverage an existing neural network architecture proven to work on problems similar to our own\n","\n","Can leverage a working network architecture which has already learned patterns on similar data to our own (often results in great results with less data)\n","\n","**Transfer learning use cases:**\n","* Computer Vision\n","  - [Imagenet](https://www.image-net.org/): image database organized according to the WordNet hierarchy in which each node of the hierarchy is depicted by hundreds and thousands of images.\n","  - Currently the best architecture is called EfficientNet\n","* Natural Language Processing:\n","  - A subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. "]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{"id":"M3ApR_wpFxu8"},"source":["## Feature Extraction"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Device found : []\n"]}],"source":["import tensorflow as tf\n","physical_device = tf.config.experimental.list_physical_devices('GPU')\n","print(f'Device found : {physical_device}') "]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1748,"status":"ok","timestamp":1659537854023,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"ahz5DxB3I99q","outputId":"62f97f2e-13e8-4016-cc2b-d55508f31ffa"},"outputs":[{"name":"stdout","output_type":"stream","text":["File ‘../Downloads/10_food_classes_10_percent.zip’ already there; not retrieving.\n","\n"]}],"source":["# Get Data (10% of 10 food classes from Food101)\n","import zipfile\n","\n","# Download data\n","!wget -nc -P ../Downloads/ https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","\n","# Unzip\n","zip_ref = zipfile.ZipFile('../Downloads/10_food_classes_10_percent.zip')\n","zip_ref.extractall(path='../Downloads/')\n","zip_ref.close()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1659538302775,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"hSNIh18_L8BJ","outputId":"8a35c7f8-0ad5-43f3-c1b3-ec3c9c5fd4b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 2 directories and 0 images in '../Downloads/10_food_classes_10_percent'.\n","There are 10 directories and 0 images in '../Downloads/10_food_classes_10_percent/test'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/grilled_salmon'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/chicken_curry'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/hamburger'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/ice_cream'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/ramen'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/sushi'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/chicken_wings'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/pizza'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/steak'.\n","There are 0 directories and 250 images in '../Downloads/10_food_classes_10_percent/test/fried_rice'.\n","There are 10 directories and 0 images in '../Downloads/10_food_classes_10_percent/train'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/grilled_salmon'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/chicken_curry'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/hamburger'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/ice_cream'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/ramen'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/sushi'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/chicken_wings'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/pizza'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/steak'.\n","There are 0 directories and 75 images in '../Downloads/10_food_classes_10_percent/train/fried_rice'.\n"]}],"source":["import os\n","\n","# Walk through 10 percent data directory and list number of files\n","for dirpath, dirnames, filenames in os.walk('../Downloads/10_food_classes_10_percent'):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"]},{"cell_type":"markdown","metadata":{"id":"n4-U7r-XN5uP"},"source":["### Create data loaders (preparing the data using `ImageDataGenerator`)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":455,"status":"ok","timestamp":1659538709661,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"OU7cCZseMksN","outputId":"c7432ea3-5eca-4a43-a112-c979ccfb4b6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training images:\n","Found 750 images belonging to 10 classes.\n","Testing images:\n","Found 2500 images belonging to 10 classes.\n"]}],"source":["# Setup data inputs\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","IMAGE_SHAPE = (224, 224)\n","BATCH_SIZE = 32\n","\n","train_dir = '../Downloads/10_food_classes_10_percent/train/'\n","test_dir = '../Downloads/10_food_classes_10_percent/test/'\n","\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","print('Training images:')\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n","                                                          target_size=IMAGE_SHAPE,\n","                                                          batch_size=BATCH_SIZE,\n","                                                          class_mode='categorical')\n","\n","print('Testing images:')\n","test_data = test_datagen.flow_from_directory(test_dir,\n","                                             target_size=IMAGE_SHAPE,\n","                                             batch_size=BATCH_SIZE,\n","                                             class_mode='categorical')"]},{"cell_type":"markdown","metadata":{"id":"ih93HQx4Nz5g"},"source":["### Setting up callbacks\n","\n","callbacks are extra functionality you can add to your models to be performed during or after training.  Some of the most popular callbacks:\n","* Tracking experiments with the `TensorBoard()` callback\n","  - Log the performance of multiple models and then view and compare these models in a visual way on TensorBoard (a dashboard for inspecting neural network parameters).  Helpful to compare the results of different models on your data.\n","* Model checkpoint with the `ModelCheckpoint()` callback\n","  - Save your model as it trains so you can stop training if needed and come back to continue where you left off.  Helpful if training takes a long time and can't be done in one sitting.\n","* Stopping a model from training (before it trains too long and overfits) with the `EarlyStopping()` callback\n","  - Leave your model training for an arbitrary amount of time and have it stop training automaticaly when it ceases to improve.  Helpful when you've got a large dataset and don't know how long training will take.\n","\n","Can be accessed via `tf.keras.callbacks`"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yiUuGX7-PXfa"},"outputs":[],"source":["# Create tensorboard callback (functionized because need to create a new one for each model)\n","import datetime\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=log_dir\n","  )\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback"]},{"cell_type":"markdown","metadata":{},"source":["### Creating models using TensorFlow Hub\n","\n","TensorFlow Hub is a repo of trained ml models\n","\n","we can access pretrained models on: https://tfhub.dev/\n","\n","**ResNet**\n","- Deep Residual Learning for Image Recognition.\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Compare the following two models\n","resnet_url = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5'\n","efficientnet_url = 'https://tfhub.dev/google/efficientnet/b0/feature_vector/1'\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# Import dependencies\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# make a create_model() function to create a model from a URL\n","def create_model(model_url, num_classes=10):\n","    \"\"\"\n","    Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n","\n","    Args:\n","        model_url (str): A TensorFlow Hub feature extraction URL.\n","        num_classes (int): Number of output neurons in the output layer, \n","            should be equal to number of target classes, default 10.as_integer_ratio\n","    Returns:\n","        An uncompiled Keras Sequential model with model_url as feature extractor\n","        layer and Dense output layer with num_classes output neurons.\n","    \"\"\"\n","    # Create the model\n","    model = tf.keras.Sequential()\n","    # Create Sequential layer from existing url\n","    feature_extractor_layer = hub.KerasLayer(model_url, \n","            trainable=False,\n","            name=\"feature_extraction_layer\",\n","            input_shape=IMAGE_SHAPE + (3,)\n","        ) # freeze the already learned patterns\n","    # Create layers\n","    output_layer = layers.Dense(num_classes, activation='softmax', name='output_layer')\n","    \n","    # Add layers to the model\n","    model.add(feature_extractor_layer)\n","    model.add(output_layer)\n","\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["### Creating and testing ResNet TensorFlow Hub Feature Extraction model"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /home/gcq/miniconda3/envs/directml/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:From /home/gcq/miniconda3/envs/directml/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","feature_extraction_layer (Ke (None, 2048)              23564800  \n","_________________________________________________________________\n","output_layer (Dense)         (None, 10)                20490     \n","=================================================================\n","Total params: 23,585,290\n","Trainable params: 20,490\n","Non-trainable params: 23,564,800\n","_________________________________________________________________\n"]}],"source":["# Create ResNet model\n","resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n","resnet_model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Compile our resnet model\n","resnet_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Saving TensorBoard log files to: ../tensorflow_hub/resnet50V2/20220803-135401\n","WARNING:tensorflow:Issue encountered when serializing variables.\n","Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n","'list' object has no attribute 'name'\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Issue encountered when serializing variables.\n","Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n","'list' object has no attribute 'name'\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","23/24 [===========================>..] - ETA: 0s - loss: 1.8248 - acc: 0.4171Epoch 1/5\n","79/24 [==================================================================================================] - 9s 110ms/step - loss: 0.9203 - acc: 0.6692\n","24/24 [==============================] - 15s 646ms/step - loss: 1.7885 - acc: 0.4267 - val_loss: 1.0938 - val_acc: 0.6692\n","Epoch 2/5\n","23/24 [===========================>..] - ETA: 0s - loss: 0.8586 - acc: 0.7563Epoch 1/5\n","79/24 [==================================================================================================] - 7s 91ms/step - loss: 0.7258 - acc: 0.7488\n","24/24 [==============================] - 9s 360ms/step - loss: 0.8545 - acc: 0.7573 - val_loss: 0.8027 - val_acc: 0.7488\n","Epoch 3/5\n","23/24 [===========================>..] - ETA: 0s - loss: 0.5871 - acc: 0.8384Epoch 1/5\n","79/24 [==================================================================================================] - 7s 93ms/step - loss: 0.6343 - acc: 0.7624\n","24/24 [==============================] - 9s 366ms/step - loss: 0.5872 - acc: 0.8387 - val_loss: 0.7261 - val_acc: 0.7624\n","Epoch 4/5\n","23/24 [===========================>..] - ETA: 0s - loss: 0.4677 - acc: 0.8816Epoch 1/5\n","79/24 [==================================================================================================] - 7s 93ms/step - loss: 0.6092 - acc: 0.7752\n","24/24 [==============================] - 9s 361ms/step - loss: 0.4620 - acc: 0.8827 - val_loss: 0.6819 - val_acc: 0.7752\n","Epoch 5/5\n","23/24 [===========================>..] - ETA: 0s - loss: 0.3739 - acc: 0.9039Epoch 1/5\n","79/24 [==================================================================================================] - 7s 92ms/step - loss: 0.5269 - acc: 0.7832\n","24/24 [==============================] - 9s 358ms/step - loss: 0.3719 - acc: 0.9067 - val_loss: 0.6563 - val_acc: 0.7832\n"]}],"source":["# Fit the model\n","resnet_history = resnet_model.fit(train_data_10_percent,\n","                                  epochs=5,\n","                                  steps_per_epoch=len(train_data_10_percent),\n","                                  validation_data=test_data,\n","                                  validation_steps=len(test_data),\n","                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n","                                  callbacks=[create_tensorboard_callback(dir_name=\"../tensorflow_hub\", # save experiment logs here\n","                                                                         experiment_name=\"resnet50V2\")]) # name of log files"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMy01CJ731Qw+w86IZWaSdP","collapsed_sections":[],"name":"04_transfer_learning.ipynb","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.6.13 ('directml')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"},"vscode":{"interpreter":{"hash":"4c179f5f00e546169410edbb1f0aaf45df98c7fd11ac06763c585ffbea32bb02"}}},"nbformat":4,"nbformat_minor":0}
