{"cells":[{"cell_type":"markdown","metadata":{"id":"afs1LvnuFcV6"},"source":["# Transfer Learning\n","\n","**Transfer Learning:**\n","\n","A research problem in machine learning that focuses on storing knowledge gained while solving one problem and applying it to a different but related problem. \n","\n","Can leverage an existing neural network architecture proven to work on problems similar to our own\n","\n","Can leverage a working network architecture which has already learned patterns on similar data to our own (often results in great results with less data)\n","\n","**Transfer learning use cases:**\n","* Computer Vision\n","  - [Imagenet](https://www.image-net.org/): image database organized according to the WordNet hierarchy in which each node of the hierarchy is depicted by hundreds and thousands of images.\n","  - Currently the best architecture is called EfficientNet\n","* Natural Language Processing:\n","  - A subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. "]},{"cell_type":"markdown","metadata":{"id":"M3ApR_wpFxu8"},"source":["## Feature Extraction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import  tensorflow.compat.v1 as tf\n","physical_device = tf.config.experimental.list_physical_devices('GPU')\n","print(f'Device found : {physical_device}') "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1748,"status":"ok","timestamp":1659537854023,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"ahz5DxB3I99q","outputId":"62f97f2e-13e8-4016-cc2b-d55508f31ffa"},"outputs":[],"source":["# Get Data (10% of 10 food classes from Food101)\n","import zipfile\n","\n","# Download data\n","!wget -nc -P ../Downloads/ https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n","\n","# Unzip\n","zip_ref = zipfile.ZipFile('../Downloads/10_food_classes_10_percent.zip')\n","zip_ref.extractall(path='../Downloads/')\n","zip_ref.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":132,"status":"ok","timestamp":1659538302775,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"hSNIh18_L8BJ","outputId":"8a35c7f8-0ad5-43f3-c1b3-ec3c9c5fd4b7"},"outputs":[],"source":["import os\n","\n","# Walk through 10 percent data directory and list number of files\n","for dirpath, dirnames, filenames in os.walk('../Downloads/10_food_classes_10_percent'):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"]},{"cell_type":"markdown","metadata":{"id":"n4-U7r-XN5uP"},"source":["### Create data loaders (preparing the data using `ImageDataGenerator`)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":455,"status":"ok","timestamp":1659538709661,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"OU7cCZseMksN","outputId":"c7432ea3-5eca-4a43-a112-c979ccfb4b6c"},"outputs":[],"source":["# Setup data inputs\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","IMAGE_SHAPE = (224, 224)\n","BATCH_SIZE = 32\n","\n","train_dir = '../Downloads/10_food_classes_10_percent/train/'\n","test_dir = '../Downloads/10_food_classes_10_percent/test/'\n","\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","print('Training images:')\n","train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n","                                                          target_size=IMAGE_SHAPE,\n","                                                          batch_size=BATCH_SIZE,\n","                                                          class_mode='categorical')\n","\n","print('Testing images:')\n","test_data = test_datagen.flow_from_directory(test_dir,\n","                                             target_size=IMAGE_SHAPE,\n","                                             batch_size=BATCH_SIZE,\n","                                             class_mode='categorical')"]},{"cell_type":"markdown","metadata":{"id":"ih93HQx4Nz5g"},"source":["### Setting up callbacks\n","\n","callbacks are extra functionality you can add to your models to be performed during or after training.  Some of the most popular callbacks:\n","* Tracking experiments with the `TensorBoard()` callback\n","  - Log the performance of multiple models and then view and compare these models in a visual way on TensorBoard (a dashboard for inspecting neural network parameters).  Helpful to compare the results of different models on your data.\n","* Model checkpoint with the `ModelCheckpoint()` callback\n","  - Save your model as it trains so you can stop training if needed and come back to continue where you left off.  Helpful if training takes a long time and can't be done in one sitting.\n","* Stopping a model from training (before it trains too long and overfits) with the `EarlyStopping()` callback\n","  - Leave your model training for an arbitrary amount of time and have it stop training automaticaly when it ceases to improve.  Helpful when you've got a large dataset and don't know how long training will take.\n","\n","Can be accessed via `tf.keras.callbacks`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yiUuGX7-PXfa"},"outputs":[],"source":["# Create tensorboard callback (functionized because need to create a new one for each model)\n","import datetime\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=log_dir\n","  )\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback"]},{"cell_type":"markdown","metadata":{},"source":["### Creating models using TensorFlow Hub\n","\n","TensorFlow Hub is a repo of trained ml models\n","\n","we can access pretrained models on: https://tfhub.dev/\n","\n","**ResNet**\n","- Deep Residual Learning for Image Recognition.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compare the following two models\n","resnet_url = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5'\n","efficientnet_url = 'https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1'\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import dependencies\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from tensorflow.keras import layers"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# make a create_model() function to create a model from a URL\n","def create_model(model_url, num_classes=10):\n","    \"\"\"\n","    Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n","\n","    Args:\n","        model_url (str): A TensorFlow Hub feature extraction URL.\n","        num_classes (int): Number of output neurons in the output layer, \n","            should be equal to number of target classes, default 10.as_integer_ratio\n","    Returns:\n","        An uncompiled Keras Sequential model with model_url as feature extractor\n","        layer and Dense output layer with num_classes output neurons.\n","    \"\"\"\n","    # Create the model\n","    model = tf.keras.Sequential()\n","    # Create Sequential layer from existing url\n","    feature_extractor_layer = hub.KerasLayer(model_url, \n","            trainable=False,\n","            name=\"feature_extraction_layer\",\n","            input_shape=IMAGE_SHAPE + (3,)\n","        ) # freeze the already learned patterns\n","    # Create layers\n","    output_layer = layers.Dense(num_classes, activation='softmax', name='output_layer')\n","    \n","    # Add layers to the model\n","    model.add(feature_extractor_layer)\n","    model.add(output_layer)\n","\n","    return model\n"]},{"cell_type":"markdown","metadata":{},"source":["### Creating and testing ResNet TensorFlow Hub Feature Extraction model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create ResNet model\n","resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)\n","resnet_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compile our resnet model\n","resnet_model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Fit the model\n","resnet_history = resnet_model.fit(train_data_10_percent,\n","                                  epochs=5,\n","                                  steps_per_epoch=len(train_data_10_percent),\n","                                  validation_data=test_data,\n","                                  validation_steps=len(test_data),\n","                                  # Add TensorBoard callback to model (callbacks parameter takes a list)\n","                                  callbacks=[create_tensorboard_callback(dir_name=\"../tensorflow_hub\", # save experiment logs here\n","                                                                         experiment_name=\"resnet50v2\")]) # name of log files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create a function to plot our loss curves...\n","# Note: you could put this in a script and import it when needed.\n","\n","import matplotlib.pyplot as plt\n","\n","# Plot the validation and training curves\n","def plot_accuracy_loss_curves(history):\n","    \"\"\"\n","    Returns separate loss curves for training and validation metrics.\n","\n","    Args:\n","        history: TensorFlow History object\n","\n","    Returns:\n","        Plots of training/validation loss and accuracy metrics.\n","    \"\"\"\n","\n","    loss = history.history[\"loss\"]\n","    val_loss = history.history[\"val_loss\"]\n","\n","    accuracy = history.history[\"accuracy\"]\n","    val_accuracy = history.history[\"val_accuracy\"]\n","\n","    epochs = range(len(history.history[\"loss\"]))\n","\n","    # Plot loss\n","    plt.plot(epochs, loss, label=\"training_loss\")\n","    plt.plot(epochs, val_loss, label=\"val_loss\")\n","    plt.title(\"Loss\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.figure()\n","    plt.plot(epochs, accuracy, label=\"training_accuracy\")\n","    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n","    plt.title(\"Accuracy\")\n","    plt.xlabel(\"Epochs\")\n","    plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_accuracy_loss_curves(history=resnet_history)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Creating and testing EfficientNetB0 TensorFlow Hub Feature Extraction model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_data_10_percent.num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create EfficientNetB0 feature extractor model\n","efficientnet_model = create_model(model_url=efficientnet_url,\n","                                  num_classes=train_data_10_percent.num_classes)\n","\n","# Compile\n","efficientnet_model.compile(loss=\"categorical_crossentropy\",\n","                            optimizer=tf.keras.optimizers.Adam(),\n","                            metrics=[\"accuracy\"])\n","\n","# Fit to 10% of training data\n","efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n","                                                epochs=5,\n","                                                steps_per_epoch=len(train_data_10_percent),\n","                                                validation_data=test_data,\n","                                                validation_steps=len(test_data),\n","                                                callbacks=[\n","                                                    create_tensorboard_callback(dir_name=\"../tensorflow_hub\",\n","                                                        experiment_name=\"efficientnetB0\")\n","                                                ]\n","                                            )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_accuracy_loss_curves(history=efficientnet_history)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["resnet_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["efficientnet_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# How many layers does our efficientnet feature extractor have?\n","print(efficientnet_model.layers)\n","\n","# check length input weights\n","print(len(efficientnet_model.layers[0].weights))\n","\n","# check length output weights\n","print(len(efficientnet_model.layers[1].weights))"]},{"cell_type":"markdown","metadata":{},"source":["## Types of Transfer Learning\n","\n","* **\"As is\"** transfer learning - Using an existing model with no changes (e.g. using ImageNet model on 1000 ImageNet classes)\n","* **\"Feature extraction\"** transfer learning - Use the prelearned patterns of an existing model (e.g. EfficientNetB0 trained on ImageNet) and adjust the output layer for your own problem (e.g. 1000 classes -> 10 classes of food)\n","* **\"Fine-tuning\"** transfer learning - Use the patterns patterns of an existing model and \"fine-tune\" many or all of the underlying layers (including new output layers)"]},{"cell_type":"markdown","metadata":{},"source":["## Comparing our models results using TensorBoard\n","\n","**Note:** When you upload things to TensorBoard.dev, your experiments are public.  So if you're running private experiments, do not upload them to TensorBoard.dev."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Upload TensorBoard dev records via terminal\n","\n","`\n","tensorboard dev upload --logdir ./tensorflow_hub/ \\\n","    --name \"efficientnetB0 vs. resnet50v2\" \\\n","    --description \"Comparing two different TF Hub feature extraction model architectures using 10% of the training data\" \\\n","    --one_shot\n","`"]},{"cell_type":"markdown","metadata":{},"source":["Our TensorBoard experiments are uploaded publicly: https://tensorboard.dev/experiment/DpVXdXhbS1u6lpJv5DBBIQ/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check out what TensorBoard experiments we have.\n","!tensorboard dev list"]},{"cell_type":"markdown","metadata":{},"source":["### Delete an experiment from TensorBoard\n","\n","`tensorboard dev delete --experiment_id DpVXdXhbS1u6lpJv5DBBIQ`\n","\n","Confirm deletion by re-checking what experiments are left."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!tensorboard dev delete --experiment_id DpVXdXhbS1u6lpJv5DBBIQ"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!tensorboard dev list"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMy01CJ731Qw+w86IZWaSdP","collapsed_sections":[],"name":"04_transfer_learning.ipynb","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 64-bit ('miniconda3')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"215bc93be91779c90c22d9452977b07e46a2652f59eedc500a409df416ed83eb"}}},"nbformat":4,"nbformat_minor":0}
