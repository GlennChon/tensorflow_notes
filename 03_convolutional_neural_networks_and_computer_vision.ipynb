{"cells":[{"cell_type":"markdown","metadata":{"id":"tt2huFLgRS8n"},"source":["# Introduction to Convolutional Neural Networks and Computer Vision with TensorFlow\n","\n","Computer Vision: Practice of writing algorithms which can discover patterns in visual data. e.g. Camera of a self-driving car recognizing other cars in view.\n","\n","The images being worked with are from the Food101 dataset\n","(101 different classes of food): https://www.kaggle.com/dansbecker/food-101\n","\n","We've modified it to only use two classes (pizza & steak) using the image data modification notebook\n","\n","**Note:** We start with a smaller dataset so we can experiment quickly and figure out what works (or better yet what doesn't work) before scaling up."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":965,"status":"ok","timestamp":1659463797315,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"9r7qpC6dUJ-5","outputId":"a55ec6a8-a437-473f-9023-6c7986afc8d4"},"outputs":[],"source":["import zipfile\n","\n","# Get data\n","!wget -nc --no-clobber https://storage.googleapis.com/ztm_tf_course/food_vision/pizza_steak.zip\n","\n","# Unzip\n","zip_ref = zipfile.ZipFile(\"pizza_steak.zip\")\n","zip_ref.extractall()\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180,"status":"ok","timestamp":1659463797493,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"-oZB00vycTIv","outputId":"44c50917-14a1-49e8-fb71-6c92c59995d4"},"outputs":[],"source":["# Inspect data\n","!ls pizza_steak/train/pizza\n","# !ls pizza_steak/train/steak\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1659463797493,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"eYbVkTx-sZYO","outputId":"f279dd5a-cc7c-4d9d-9f7f-528d2f71079b"},"outputs":[],"source":["import os\n","# Walk through pizza_steak dir and list # of files\n","for dirpath, dirnames, filenames in os.walk('pizza_steak'):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1659463797493,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"HAjmw9l0tO8o","outputId":"b91dd3d6-d52f-49b1-f037-58ac1db1ace6"},"outputs":[],"source":["# Another way to find out how many images are in a folder\n","num_steak_images_train = len(os.listdir(\"pizza_steak/train/steak\"))\n","num_steak_images_train\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1659463797494,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Uao4zlEDtfTZ","outputId":"455160bd-1af0-4d31-b2b8-32592dc48618"},"outputs":[],"source":["# To visualize our images, first let's get the class names programmatically\n","import pathlib\n","import numpy as np\n","data_dir = pathlib.Path(\"pizza_steak/train\")\n","class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")]))\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659463797494,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Wdsl9pFLuHQu"},"outputs":[],"source":["# Visualize images\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import random\n","\n","def view_random_image(target_dir, target_class):\n","  \"\"\"\n","  Takes target_dir and target_class as strings\n","  Displays a random image witn class and shape\n","  returns the image\n","  \"\"\"\n","  # Setup the target dir (we'll view images from here)\n","  target_folder = target_dir+target_class\n","  \n","  # Get random img path\n","  random_image = random.sample(os.listdir(target_folder), 1)\n","\n","  # Read in the image and plot it using matplotlib\n","  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n","  plt.imshow(img)\n","  plt.title(target_class)\n","  plt.axis(False)\n","\n","  print(f\"Image shape: {img.shape}\")\n","  return img\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":380,"status":"ok","timestamp":1659463797872,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"iU33fEH7vrBn","outputId":"b917cac1-3743-47b0-fd6a-101de27682d4"},"outputs":[],"source":["# Try the \n","img = view_random_image(\"pizza_steak/train/\",\"pizza\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":149,"status":"ok","timestamp":1659463798592,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"ocgACtTnwA-f","outputId":"ec6c7310-0ff8-4631-f92f-bf7375232e1e"},"outputs":[],"source":["import tensorflow as tf\n","tf.constant(img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1659463798592,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"hYXQc3BOwbyL","outputId":"52604c15-6f23-403d-c46c-cd2a99a22931"},"outputs":[],"source":["# View img shape\n","img.shape # returns width, height, color channels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1659463798593,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"xvQLViYPxAcw","outputId":"0926438a-0113-43d7-c231-e4a7b034c541"},"outputs":[],"source":["# Normalize the values\n","img/255. # max pixel value 255"]},{"cell_type":"markdown","metadata":{"id":"p2pjphxBxoFt"},"source":["## An end-to-end example\n","\n","Build a convolutional neural network to find patterns in our images.\n","\n","* Load our images\n","* Preprocess our images (normalize)\n","* Build a CNN to find patterns\n","* Compile the CNN\n","* Fit the CNN to our training data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":162,"status":"ok","timestamp":1659463798752,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"XhsXDxMjx5ZE"},"outputs":[],"source":["import random\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import Sequential\n","# Created a class for creating and fitting models cuz I got sick of writing it over and over again.\n","# set the seed\n","tf.random.set_seed(42)\n","class ComputerVisionModel():\n","  def __init__(self, train_dir, test_dir, batch_size = 32, target_size=(224,224), class_mode=\"binary\", seed=42, epochs=5, rescale=1./255):\n","    self.train_dir = train_dir\n","    self.test_dir = test_dir\n","    self.batch_size = batch_size\n","    self.target_size = target_size\n","    self.class_mode = class_mode # binary or sparse, categorical, raw or multi_output, input or none\n","    self.seed = seed\n","    self.epochs = epochs\n","    # Preprocess data (normalize pixel data from images)\n","    self.train_datagen = ImageDataGenerator(rescale=rescale)\n","    self.valid_datagen = ImageDataGenerator(rescale=rescale)\n","     # Import data from directories and turn it into batches\n","    self.train_data = self.train_datagen.flow_from_directory(\n","        directory=self.train_dir, \n","        batch_size=self.batch_size,\n","        target_size=self.target_size,\n","        class_mode=self.class_mode, \n","        seed=self.seed\n","        )\n","  \n","    self.valid_data = self.valid_datagen.flow_from_directory(\n","        directory=self.test_dir, \n","        batch_size=self.batch_size,\n","        target_size=self.target_size,\n","        class_mode=self.class_mode, \n","        seed=self.seed\n","        )\n","\n","  def create_model(self, layers):\n","    \"\"\"\n","    Returns a model, takes tensorflow Sequential layers parameters\n","    \"\"\"\n","    # Build a CNN model (same as Tiny VGG on the CNN explainer website)\n","    model = Sequential(layers)\n","    return model\n","\n","  def fit(self, model):\n","    \"\"\"\n","    Returns history. Takes model and fits it\n","    \"\"\"\n","    history = model.fit(\n","        self.train_data, \n","        epochs=self.epochs,\n","        steps_per_epoch=len(self.train_data),\n","        validation_data=self.valid_data,\n","        validation_steps=len(self.valid_data)\n","        )\n","    return history\n","\n","  def plot_loss_curves(self, history):\n","    \"\"\"\n","    Returns separate loss curves for training and validation metrics, takes history\n","    \"\"\" \n","    loss = history.history[\"loss\"]\n","    val_loss = history.history[\"val_loss\"]\n","\n","    accuracy = history.history[\"accuracy\"]\n","    val_accuracy = history.history[\"val_accuracy\"]\n","\n","    epochs = range(len(history.history[\"loss\"])) # How many epochs did we run for\n","    \n","    # Plot loss\n","    plt.plot(epochs, loss, label=\"training_loss\")\n","    plt.plot(epochs, val_loss, label=\"val_loss\")\n","    plt.title(\"loss\")\n","    plt.xlabel(\"epochs\")\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.figure()\n","    plt.plot(epochs, accuracy, label=\"training_accuracy\")\n","    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n","    plt.title(\"accuracy\")\n","    plt.xlabel(\"epochs\")\n","    plt.legend()\n","\n","  def view_random_training_image(self, target_class):\n","    \"\"\"\n","    Takes target_class as string\n","    Displays a random image witn class and shape\n","    returns the image\n","    \"\"\"\n","    # Setup the target dir (we'll view images from here)\n","    target_folder = train_dir+\"/\"+target_class\n","    \n","    # Get random img path\n","    random_image = random.sample(os.listdir(target_folder), 1)\n","\n","    # Read in the image and plot it using matplotlib\n","    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n","    plt.imshow(img)\n","    plt.title(target_class)\n","    plt.axis(False)\n","\n","    print(f\"Image shape: {img.shape}\")\n","    return img\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161,"status":"ok","timestamp":1659463798912,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"6ep1g4991vOr","outputId":"39a804e8-a9be-45cb-b155-15a1646d699b"},"outputs":[],"source":["# remember to switch runtime to use GPU `runtime>change runtime type`\n","model_initializer = ComputerVisionModel(train_dir=\"pizza_steak/train\", test_dir=\"pizza_steak/test\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54132,"status":"ok","timestamp":1659463853043,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"0nO33Cjl288w","outputId":"0fba7244-3ff9-4a1d-f8bc-bd990afa6e95"},"outputs":[],"source":["model = model_initializer.create_model(layers=[\n","        tf.keras.layers.Conv2D(\n","            filters=19,\n","            kernel_size=3,\n","            activation=\"relu\",\n","            input_shape=(224, 224, 3)\n","        ),\n","        tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n","        tf.keras.layers.MaxPool2D(\n","            pool_size=2,\n","            padding=\"valid\"\n","            ),\n","        tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n","        tf.keras.layers.Conv2D(10, 3, activation=\"relu\"),\n","        tf.keras.layers.MaxPool2D(2),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","        ])\n","\n","# Compile CNN\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=tf.keras.optimizers.Adam(),\n","    metrics=[\"accuracy\"]\n","    )\n","history_1 = model_initializer.fit(model=model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1659463853043,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"6wcaQPo48Vsu","outputId":"2bae837f-3671-4de5-90e6-1f2911c08621"},"outputs":[],"source":["history_1.history"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45491,"status":"ok","timestamp":1659463898525,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"eqgzJo60UvKo","outputId":"9b9e65da-5b92-48dc-ff0b-27e4d1aa8b6b"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","# Create a 2nd model\n","# Set random seed\n","tf.random.set_seed(42)\n","\n","# Create\n","model_2 = model_initializer.create_model(\n","    layers=[\n","            tf.keras.layers.Flatten(input_shape=(224, 224, 3)), # dense layers expect a 1-dimensional vector as input\n","            tf.keras.layers.Dense(4, activation='relu'),\n","            tf.keras.layers.Dense(4, activation='relu'),\n","            tf.keras.layers.Dense(1, activation='sigmoid')\n","            ])\n","\n","# Compile CNN\n","model_2.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=tf.keras.optimizers.Adam(),\n","    metrics=[\"accuracy\"]\n","    )\n","\n","history_2 = model_initializer.fit(model=model_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45691,"status":"ok","timestamp":1659463944214,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"G4EQI7Cnb0Jo","outputId":"8504a527-50b1-40d9-d0ce-7ab5bd750b29"},"outputs":[],"source":["# Same as above, just add an extra layer and add more neurons\n","tf.random.set_seed(42)\n","\n","# Create\n","model_3 = model_initializer.create_model(\n","    layers=[\n","     tf.keras.layers.Flatten(input_shape=(224, 224, 3)),\n","     tf.keras.layers.Dense(100, activation=\"relu\"),\n","     tf.keras.layers.Dense(100, activation=\"relu\"),\n","     tf.keras.layers.Dense(100, activation=\"relu\"),\n","     tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","    ]\n",")\n","\n","# Compile\n","model_3.compile(loss='binary_crossentropy',\n","                optimizer=tf.keras.optimizers.Adam(),\n","                metrics=[\"accuracy\"])\n","\n","# Fit\n","history_3 = model_initializer.fit(model=model_3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1659463944215,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"i0bcX1lGWlK6","outputId":"8678395b-f7d8-41f2-bdeb-bdbe224d0b64"},"outputs":[],"source":["model_3.summary()"]},{"cell_type":"markdown","metadata":{"id":"m8TF8RC1Yhf4"},"source":["## Binary Classification\n","\n","1. Visualize, Visualize, Visualize\n","2. Preprocess the data (normalize)\n","3. Create a model (start with a baseline)\n","4. Fit the model\n","5. Evaluate\n","6. Adjust different parameters and improve the model\n","7. Repeat until satisfied"]},{"cell_type":"markdown","metadata":{"id":"SLC-FnWbaaEv"},"source":["### Visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":234},"executionInfo":{"elapsed":339,"status":"ok","timestamp":1659463944546,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"3G8Pul9lY_dC","outputId":"ab6c9c9f-4ddf-4f2d-a796-ba059f27366f"},"outputs":[],"source":["\n","plt.figure()\n","plt.subplot(1, 2, 1)\n","steak_img = view_random_image(\"pizza_steak/train/\", \"steak\")\n","\n","plt.subplot(1, 2, 2)\n","pizza_img = view_random_image(\"pizza_steak/train/\", \"pizza\")\n"]},{"cell_type":"markdown","metadata":{"id":"M8y7cystaDqG"},"source":["### Preprocess Data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659463944546,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"itJ60-Wyad1r"},"outputs":[],"source":["# Define directory dataset paths\n","train_dir = \"pizza_steak/train/\"\n","test_dir = \"pizza_steak/test/\""]},{"cell_type":"markdown","metadata":{"id":"ySPvUy41aoeG"},"source":["Organize the data into **batches**\n","\n","Batch: small subset of data.  Rather than look at all ~15k images at one time, a model might only look at 32 at a time.\n","\n","**It does this for a a couple of reasons:**\n","1. 15,000 images (or more) might not fit into the memory of your processor (GPU).\n","2. Trying to learn the patternsin 15k images in one hit could result in the model not being able to learn very well.\n","\n","\n","**Why batch size of 32?**\n","32 is a generally accepted mini-batch size.\n","\n","However, mini-batch size is a hyperparameter that needs to be tuned according to your data and chosen model for optimal performance.\n","\n","With smaller batch sizes the estimate of gradient in each epoch is more noisy but it helps the algorithm to avoid local minima. But it also makes training less efficient if you go too low as the weights will jump around too much and the cost will converge much more slowly."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1659463944727,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"2PhSXV7xarSz","outputId":"48f03202-9cef-4fa8-ba95-3cb7b616d7ec"},"outputs":[],"source":["# Checking the GPU\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":139,"status":"ok","timestamp":1659463944865,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"vq8P1_6rc9Kf","outputId":"bd7e2ec2-772a-4538-f50d-ab0193292c0f"},"outputs":[],"source":["# Create train and test data generator\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# When loading images, divide all pixel values by 255, this normalizes all the images\n","rescale_val = 1/255.\n","\n","model_initializer = ComputerVisionModel(\n","    train_dir=\"pizza_steak/train/\", \n","    test_dir=\"pizza_steak/test/\",\n","    batch_size = 32, \n","    target_size=(224,224), \n","    class_mode=\"binary\", \n","    seed=42, \n","    epochs=5, \n","    rescale=rescale_val\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":144,"status":"ok","timestamp":1659463945008,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"By_NA2-sf2ib","outputId":"b46ea121-de9b-4deb-ef5e-f2e8058a8d1a"},"outputs":[],"source":["images, labels = model_initializer.train_data.next() # get the 'next' batch of images/labels in train_data\n","images[:2], images[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1659463945008,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"yNnJCs05gkr_","outputId":"35e229d9-0a92-4c6a-8307-45fa521a9679"},"outputs":[],"source":["images[7], images[7].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1659463945009,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"9e-Bzgq3g4SF","outputId":"fbbfad43-b3e3-4d4e-e993-c28d6efe0c9a"},"outputs":[],"source":["# View labels for the first batch\n","labels"]},{"cell_type":"markdown","metadata":{"id":"iVWOMFBlhPs8"},"source":["###3. Create a CNN model (start with a baseline)\n","\n","A baseline is a relatively simple model or existing result that you setup when beginning a machine learning experiment.  As you keep experimenting, you try to beat the baseline.\n","\n","**Note:** In deep learning, there is almost an infinite amount of architectures you could create. So one of the best w2ays to get started is to begin with something simple and see if it works on your data and then introduce complexity as required. (look up which current model is performing best in the field of your problem)\n","\n","#### Check out [Papers With Code](https://paperswithcode.com/)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659463945009,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"WAvZ-n7Yg_6k"},"outputs":[],"source":["# Create a models\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation\n","\n","# Same as above, just add an extra layer and add more neurons\n","tf.random.set_seed(42)\n","\n","model_4 = model_initializer.create_model(\n","    layers=[\n","            Conv2D(\n","                filters=10,# number of sliding windows going across an input (higher = more complex model)\n","                kernel_size=3, # (3,3), # size of the sliding window across an input\n","                strides=1, # (1,1), # size of the step the sliding window takes across an input\n","                padding=\"valid\",\n","                activation=\"relu\",\n","                input_shape=(224, 224, 3) # input layer (specify input shape)\n","            ),\n","            Conv2D(10, 3, activation=\"relu\"),\n","            Conv2D(10, 3, activation=\"relu\"),\n","            Flatten(),\n","            Dense(1, activation=\"sigmoid\") # output layer (working with binary classification so only 1 output neuron)\n","            ])"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659463945169,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"uXXwzmdCBkBC"},"outputs":[],"source":["# Compile\n","model_4.compile(loss='binary_crossentropy',\n","                optimizer=Adam(),\n","                metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":50695,"status":"ok","timestamp":1659463995862,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"y8Szd_YECS4-","outputId":"dafce026-b98c-4bbc-a751-270cb4c2d05f"},"outputs":[],"source":["# Fit\n","history_4 = model_initializer.fit(model_4)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"elapsed":428,"status":"ok","timestamp":1659463996282,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"b-9vnA_5kTYI","outputId":"450e9930-cdac-49db-9ea4-2e3562211f97"},"outputs":[],"source":["# Evaluate - plot training curves\n","import pandas as pd\n","pd.DataFrame(history_4.history).plot(figsize=(10,7))"]},{"cell_type":"markdown","metadata":{"id":"fjw88xE21DfX"},"source":["**Note:** When a model's **validation loss starts to increase**, it's likely that the model is **overfitting** the training dataset.\n","\n","It's learning the patterns in the training dataset *too well* and thus the model's ability to generalize to unseen data will be diminished."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"elapsed":374,"status":"ok","timestamp":1659463996654,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"cDfV0_GUoTug","outputId":"b1d72754-ce10-4a50-b2b9-e6020157a333"},"outputs":[],"source":["model_initializer.plot_loss_curves(history_4)\n"]},{"cell_type":"markdown","metadata":{"id":"1QQZxC4UCQU3"},"source":["### Adjust the model parameters\n","\n","**Fitting a machine learning model comes in 3 steps:**\n","\n","1. Create a baseline\n","2. Beat the baseline by overfitting a larger model\n","3. Reduce overfitting\n","\n","**Ways to induce overfitting:**\n","\n","* Increase # of conv layers\n","* Increase # of conv filters\n","* Add another dense layer to the output of our flattened layer\n","\n","**Ways to reduce overfitting:**\n","\n","* Add data augmentation\n","* Add regularization layers (such as MaxPool2D)\n","* Add more data...\n","\n","**Note:** Reducing overfitting is also known as **regularization**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659463996654,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Ntevu2RsC0D8"},"outputs":[],"source":["# Same as above, just add an extra layer and add more neurons\n","tf.random.set_seed(42)\n","# Create a new model\n","model_5 = model_initializer.create_model(\n","    layers=[\n","            Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n","            MaxPool2D(pool_size=2),\n","            Conv2D(10, 3, activation=\"relu\"),\n","            MaxPool2D(), \n","            Conv2D(10, 3, activation=\"relu\"),\n","            MaxPool2D(),\n","            Flatten(),\n","            Dense(1, activation=\"sigmoid\")\n","    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47191,"status":"ok","timestamp":1659464043844,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"HWNuFWQ9DfVV","outputId":"9b4c0906-4588-4a41-bf53-ecf55f3e9943"},"outputs":[],"source":["# Compile\n","model_5.compile(loss='binary_crossentropy',\n","                optimizer=Adam(),\n","                metrics=[\"accuracy\"])\n","# Fit\n","history_5 = model_initializer.fit(model_5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1659464044343,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"rRFHnpPzDtHr","outputId":"2204cc46-62d9-457b-aec4-fe2358044073"},"outputs":[],"source":["model_initializer.plot_loss_curves(history_5), model_5.summary()"]},{"cell_type":"markdown","metadata":{"id":"2gWQ0ncpF5E3"},"source":["### MaxPool2D()\n","Selects 1 max pixel value from all pixels within range of kernel\n","\n","### Conv2D\n","Slides matrix of weights, multiplies by pixel value then sums all results."]},{"cell_type":"markdown","metadata":{"id":"0tZlzmuiHQ0c"},"source":["### Data Augmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659464044343,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"BCLN570tHS1k"},"outputs":[],"source":["# Create imageDataGenerator training instance with data augmentation\n","train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n","                                             rotation_range=0.2, # how much do you want to rotate an image\n","                                             shear_range=0.2, # how much do you want to shear an image?\n","                                             zoom_range=0.2, # how much do you want to zoom?\n","                                             width_shift_range=0.2, # move image around on X axis\n","                                             height_shift_range=0.3, # move image around on Y axis\n","                                             horizontal_flip=True) # do you want to flip an image?\n","\n","# Create ImageDataGenerator without data augmentation\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","# Create ImageDataGenerator without data augmentation for the test dataset\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hTlm35N-1T_E"},"source":["**Question:** What is data augmentation?\n","\n","Data Augmentation: the process of altering our training data, leading it to have more diversity and in turn allowing our models to learn more generalizable (hopefully) patterns.\n","\n","Altering might mean adjusting the rotation of an image, flipping it, cropping it, or something similar.\n","\n","Let's write some code to visualize data augmentation..."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":304,"status":"ok","timestamp":1659464044645,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Es3E6ZKv1x48","outputId":"7fc6608a-aa20-41bd-affa-70c171b1a72f"},"outputs":[],"source":["# Import data and augment it from training directory\n","\n","IMG_SIZE = (224, 224)\n","print(\"Augmented training data:\")\n","train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n","                                                                   target_size=IMG_SIZE,\n","                                                                   batch_size=32,\n","                                                                   class_mode=\"binary\",\n","                                                                   shuffle=False) # for demonstration purposes only, usually true\n","\n","# Create non-augmented train data batches\n","print(\"Non-augmented training data:\")\n","train_data = train_datagen.flow_from_directory(train_dir, \n","                                              target_size=IMG_SIZE,\n","                                              batch_size=32,\n","                                              class_mode=\"binary\",\n","                                              shuffle=False)     \n","# Create non-augmented test data batches\n","print(\"Non-augmented test data:\")\n","test_data = test_datagen.flow_from_directory(test_dir, \n","                                              target_size=IMG_SIZE,\n","                                              batch_size=32,\n","                                              class_mode=\"binary\")                                                      "]},{"cell_type":"markdown","metadata":{"id":"m9BbG8r224c3"},"source":["**Note:** Data augmentation is usually only performed on the training data. Using `ImageDataGenerator` build-in data augmentation parameters, our images are left as they are in the directories but are modified as they're loaded into the model.\n","\n","Let's visualize the augmented data:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":588,"status":"ok","timestamp":1659464045232,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"55XPDYiO3NRD"},"outputs":[],"source":["# Get sample augmented data batches\n","images, labels = train_data.next()\n","augmented_images, augmented_labels = train_data_augmented.next() # note: labels aren't augmented, only data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":546},"executionInfo":{"elapsed":328,"status":"ok","timestamp":1659464045557,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"0S4hDzXH3nmE","outputId":"04024c32-aba7-4974-e0c7-d3b396cb8b53"},"outputs":[],"source":["# Show original image and augmented image\n","import random\n","random_number = random.randint(0, 31) # bath sizes are 32...\n","\n","print(f'Showing image number: {random_number}')\n","plt.imshow(images[random_number])\n","plt.title(f'Original Image')\n","plt.axis(False)\n","plt.figure()\n","\n","\n","plt.imshow(augmented_images[random_number])\n","plt.title(f'Augmented Image')\n","plt.axis(False)\n"]},{"cell_type":"markdown","metadata":{"id":"UY-gr9c4Alrg"},"source":["<table>\n","<colgroup><col width=\"214px\"><col></colgroup>\n","<tbody><tr><th colspan=\"2\"><h2><span>ImageDataGenerator Args</span></h2></th></tr>\n","<tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">featurewise_<wbr>center</code><a id=\"featurewise_center\"></a>\n","</td>\n","<td>\n","Boolean. Set input mean to 0 over the dataset,\n","feature-wise.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">samplewise_<wbr>center</code><a id=\"samplewise_center\"></a>\n","</td>\n","<td>\n","Boolean. Set each sample mean to 0.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">featurewise_<wbr>std_<wbr>normalization</code><a id=\"featurewise_std_normalization\"></a>\n","</td>\n","<td>\n","Boolean. Divide inputs by std of the\n","dataset, feature-wise.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">samplewise_<wbr>std_<wbr>normalization</code><a id=\"samplewise_std_normalization\"></a>\n","</td>\n","<td>\n","Boolean. Divide each input by its std.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">zca_<wbr>epsilon</code><a id=\"zca_epsilon\"></a>\n","</td>\n","<td>\n","epsilon for ZCA whitening. Default is 1e-6.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">zca_<wbr>whitening</code><a id=\"zca_whitening\"></a>\n","</td>\n","<td>\n","Boolean. Apply ZCA whitening.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">rotation_<wbr>range</code><a id=\"rotation_range\"></a>\n","</td>\n","<td>\n","Int. Degree range for random rotations.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">width_<wbr>shift_<wbr>range</code><a id=\"width_shift_range\"></a>\n","</td>\n","<td>\n","Float, 1-D array-like or int<p></p>\n","\n","<ul>\n","<li>float: fraction of total width, if &lt; 1, or pixels if &gt;= 1.</li>\n","<li>1-D array-like: random elements from the array.</li>\n","<li>int: integer number of pixels from interval <code translate=\"no\" dir=\"ltr\">(-width_shift_range,\n","+width_shift_range)</code> - With <code translate=\"no\" dir=\"ltr\">width_shift_range=2</code> possible values\n","are integers <code translate=\"no\" dir=\"ltr\">[-1, 0, +1]</code>, same as with <code translate=\"no\" dir=\"ltr\">width_shift_range=[-1, 0,\n","+1]</code>, while with <code translate=\"no\" dir=\"ltr\">width_shift_range=1.0</code> possible values are floats\n","in the interval [-1.0, +1.0).\n","</li></ul></td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">height_<wbr>shift_<wbr>range</code><a id=\"height_shift_range\"></a>\n","</td>\n","<td>\n","Float, 1-D array-like or int\n","<li>float: fraction of total height, if &lt; 1, or pixels if &gt;= 1.</li>\n","<li>1-D array-like: random elements from the array.</li>\n","<li>int: integer number of pixels from interval <code translate=\"no\" dir=\"ltr\">(-height_shift_range,\n","+height_shift_range)</code> - With <code translate=\"no\" dir=\"ltr\">height_shift_range=2</code> possible values\n","are integers <code translate=\"no\" dir=\"ltr\">[-1, 0, +1]</code>, same as with <code translate=\"no\" dir=\"ltr\">height_shift_range=[-1, 0,\n","+1]</code>, while with <code translate=\"no\" dir=\"ltr\">height_shift_range=1.0</code> possible values are floats\n","in the interval [-1.0, +1.0).\n","</li></td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">brightness_<wbr>range</code><a id=\"brightness_range\"></a>\n","</td>\n","<td>\n","Tuple or list of two floats. Range for picking a\n","brightness shift value from.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">shear_<wbr>range</code><a id=\"shear_range\"></a>\n","</td>\n","<td>\n","Float. Shear Intensity (Shear angle in counter-clockwise\n","direction in degrees)\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">zoom_<wbr>range</code><a id=\"zoom_range\"></a>\n","</td>\n","<td>\n","Float or [lower, upper]. Range for random zoom. If a float,\n","<code translate=\"no\" dir=\"ltr\">[lower,<wbr> upper] = [1-zoom_<wbr>range,<wbr> 1+zoom_<wbr>range]</code>.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">channel_<wbr>shift_<wbr>range</code><a id=\"channel_shift_range\"></a>\n","</td>\n","<td>\n","Float. Range for random channel shifts.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">fill_<wbr>mode</code><a id=\"fill_mode\"></a>\n","</td>\n","<td>\n","One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Default is\n","'nearest'. Points outside the boundaries of the input are filled\n","according to the given mode:\n","<ul>\n","<li>'constant': kkkkkkkk|abcd|kkkkkkkk (cval=k)</li>\n","<li>'nearest':  aaaaaaaa|abcd|dddddddd</li>\n","<li>'reflect':  abcddcba|abcd|dcbaabcd</li>\n","<li>'wrap':  abcdabcd|abcd|abcdabcd\n","</li></ul></td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">cval</code><a id=\"cval\"></a>\n","</td>\n","<td>\n","Float or Int. Value used for points outside the boundaries when\n","<code translate=\"no\" dir=\"ltr\">fill_<wbr>mode = \"constant\"</code>.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">horizontal_<wbr>flip</code><a id=\"horizontal_flip\"></a>\n","</td>\n","<td>\n","Boolean. Randomly flip inputs horizontally.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">vertical_<wbr>flip</code><a id=\"vertical_flip\"></a>\n","</td>\n","<td>\n","Boolean. Randomly flip inputs vertically.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">rescale</code><a id=\"rescale\"></a>\n","</td>\n","<td>\n","rescaling factor. Defaults to None. If None or 0, no rescaling is\n","applied, otherwise we multiply the data by the value provided (after\n","applying all other transformations).\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">preprocessing_<wbr>function</code><a id=\"preprocessing_function\"></a>\n","</td>\n","<td>\n","function that will be applied on each input. The\n","function will run after the image is resized and augmented.\n","The function should take one argument: one image (Numpy tensor with\n","rank 3), and should output a Numpy tensor with the same shape.\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">data_<wbr>format</code><a id=\"data_format\"></a>\n","</td>\n","<td>\n","Image data format, either \"channels_first\" or\n","\"channels_last\". \"channels_last\" mode means that the images should have\n","shape <code translate=\"no\" dir=\"ltr\">(samples,<wbr> height,<wbr> width,<wbr> channels)</code>, \"channels_first\" mode means\n","that the images should have shape <code translate=\"no\" dir=\"ltr\">(samples,<wbr> channels,<wbr> height,<wbr> width)</code>.\n","It defaults to the <code translate=\"no\" dir=\"ltr\">image_<wbr>data_<wbr>format</code> value found in your Keras config\n","file at <code translate=\"no\" dir=\"ltr\">~/<wbr>.<wbr>keras/<wbr>keras.<wbr>json</code>. If you never set it, then it will be\n","\"channels_last\".\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">validation_<wbr>split</code><a id=\"validation_split\"></a>\n","</td>\n","<td>\n","Float. Fraction of images reserved for validation\n","(strictly between 0 and 1).\n","</td>\n","</tr><tr>\n","<td>\n","<code translate=\"no\" dir=\"ltr\">dtype</code><a id=\"dtype\"></a>\n","</td>\n","<td>\n","Dtype to use for the generated arrays.\n","</td>\n","</tr>\n","</tbody></table>"]},{"cell_type":"markdown","metadata":{"id":"C4qN15ITC1aM"},"source":["### Build a model and train using augmented data\n","\n","Same as model 5 but using augmented data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":134037,"status":"ok","timestamp":1659464179590,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"IRPgDLjKBINz","outputId":"754ceab9-fbe1-4162-8072-14a4723644a5"},"outputs":[],"source":["# Import data and augment it from training directory\n","\n","IMG_SIZE = (224, 224)\n","print(\"Augmented training data:\")\n","train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n","                                                                   target_size=IMG_SIZE,\n","                                                                   batch_size=32,\n","                                                                   class_mode=\"binary\",\n","                                                                   shuffle=True) \n","\n","# Create non-augmented train data batches\n","print(\"Non-augmented training data:\")\n","train_data_shuffled = train_datagen.flow_from_directory(train_dir, \n","                                              target_size=IMG_SIZE,\n","                                              batch_size=32,\n","                                              class_mode=\"binary\",\n","                                              shuffle=True)     \n","# Create non-augmented test data batches\n","print(\"Non-augmented test data:\")\n","test_data = test_datagen.flow_from_directory(test_dir, \n","                                              target_size=IMG_SIZE,\n","                                              batch_size=32,\n","                                              class_mode=\"binary\")     \n","\n","# Create new Model\n","model_6 = model_initializer.create_model(layers=[\n","            Conv2D(10, 3, activation=\"relu\", input_shape=(224, 224, 3)),\n","            MaxPool2D(pool_size=2),\n","            Conv2D(10, 3, activation=\"relu\"),\n","            MaxPool2D(), \n","            Conv2D(10, 3, activation=\"relu\"),\n","            MaxPool2D(),\n","            Flatten(),\n","            Dense(1, activation=\"sigmoid\")\n","    ])\n","# Compile\n","model_6.compile(loss='binary_crossentropy',\n","                optimizer=Adam(),\n","                metrics=[\"accuracy\"])\n","# Fit\n","\n","history_6 = model_6.fit(\n","    train_data_augmented, \n","    epochs=5,\n","    steps_per_epoch=len(train_data_augmented),\n","    validation_data=test_data,\n","    validation_steps=len(test_data)\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"elapsed":437,"status":"ok","timestamp":1659464180018,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"d5LVKIdpCWu_","outputId":"4c64ddee-969d-4a65-fbee-5e9da4857a6e"},"outputs":[],"source":["# Check training curves\n","model_initializer.plot_loss_curves(history_6)"]},{"cell_type":"markdown","metadata":{"id":"tkupvPqzE_mi"},"source":["### Repeat until satisfied\n","\n","Options:\n","* Increase the number of model layers (e.g. add more `Conv2D` / `MaxPool2D` layers)\n","* Increase the number of filters in each covolutional layer\n","* Train for longer (more epochs)\n","* Find an ideal learning rate\n","* Get more data (give the model more opportunities to learn)\n","* Use **transfer learning** to leverage what another image model has learned and adjust it for our own use case.\n","\n","**Practice:** Recreate the model on the CNN explainer webiste (same as model_1) and see how it performs on the augmented shuffled training data.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":114441,"status":"ok","timestamp":1659464294458,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"cLgTeGfHSxuW","outputId":"1cd8dfb5-26a6-49e8-d1ef-0e7e355f9efa"},"outputs":[],"source":["# Create the model (same as model_5 and model_6)\n","model_7 = Sequential([\n","  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n","  MaxPool2D(),\n","  Conv2D(10, 3, activation='relu'),\n","  MaxPool2D(),\n","  Conv2D(10, 3, activation='relu'),\n","  MaxPool2D(),\n","  Flatten(),\n","  Dense(1, activation='sigmoid')\n","])\n","\n","# Compile the model\n","model_7.compile(loss='binary_crossentropy',\n","                optimizer=Adam(),\n","                metrics=['accuracy'])\n","\n","# Fit the model\n","history_7 = model_7.fit(train_data_augmented_shuffled, # now the augmented data is shuffled\n","                        epochs=5,\n","                        steps_per_epoch=len(train_data_augmented_shuffled),\n","                        validation_data=test_data,\n","                        validation_steps=len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":498,"status":"ok","timestamp":1659464294946,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"1lQV9Z2mFnKt","outputId":"28eae18b-7ab7-4b97-9732-db706b9c9883"},"outputs":[],"source":["# Create a function to import and resize an img to a size that's usable in our model\n","# Download custom image\n","import matplotlib.image as mpimg\n","!wget -nc --no-clobber https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n","\n","def load_and_prep_image(filename, img_shape=224):\n","  \"\"\"\n","  Reads an image from filename, \n","  turns it into a tensor and reshapes it to (img_shape, img_shape, color_channels)\n","  \"\"\"\n","\n","  # Read in the image\n","  img = tf.io.read_file(filename)\n","  # Decode the read file into a tensor\n","  img = tf.image.decode_jpeg(img) \n","  # Resize\n","  img = tf.image.resize(img,size=[img_shape, img_shape])\n","  # Rescale the image (get all values between 0 and 1 {normalized})\n","  img = img/255.\n","  return img\n","# Load in and preprocess a custom image\n","steak = load_and_prep_image(filename='03-steak.jpeg')\n","\n","pred=model_7.predict(tf.expand_dims(steak, axis=0))\n","        "]},{"cell_type":"markdown","metadata":{"id":"rpnUbJoIMMCT"},"source":["Looks like our custome image is being put through our model, however, it currently outputs a prediction probability, wouldn't it be nice if we coudl visualize the image as well as the model's prediction?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1659464294947,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"HKHecJGcMXK-","outputId":"89ddbcd4-4b07-485d-c09c-949e5dcb22a3"},"outputs":[],"source":["# Remind ourself of the class names\n","class_names\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1659464294947,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"FYfmBN9EMhIc","outputId":"0ee6b1d2-bc8e-42cd-90af-692ae8fae01d"},"outputs":[],"source":["# We can index the predicted class by rounding the prediction probability and indexing on the class names\n","pred_class = class_names[int(tf.round(pred)[0][0])]\n","pred_class"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1659464294947,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"8iLIOqzIMzKq"},"outputs":[],"source":["def pred_and_plot(model, filename, class_names):\n","  \"\"\"\n","  Imports an image located at filename, makes a prediction on it with\n","  a trained model and plots the image with the predicted class as the title.\n","  \"\"\"\n","  # Import the target image and preprocess it\n","  img = load_and_prep_image(filename)\n","\n","  # Make a prediction\n","  pred = model.predict(tf.expand_dims(img, axis=0))\n","\n","  # Get the predicted class\n","  pred_class = class_names[int(tf.round(pred)[0][0])]\n","\n","  # Plot the image and predicted class\n","  plt.imshow(img)\n","  plt.title(f\"Prediction: {pred_class}\")\n","  plt.axis(False);\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"executionInfo":{"elapsed":424,"status":"ok","timestamp":1659464295368,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"8f56H1FXNYio","outputId":"00ce28a1-d434-48ea-8ffa-ad9ff522a321"},"outputs":[],"source":["# Test our model on a custom image\n","pred_and_plot(model_7, \"03-steak.jpeg\", class_names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299},"executionInfo":{"elapsed":480,"status":"ok","timestamp":1659464295846,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"_0Z3CaEIR87e","outputId":"e821e98f-a95b-4f2a-8a52-5f27ce582657"},"outputs":[],"source":["# Download another test custom image and make a prediction on it\n","!wget -nc --no-clobber https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n","pizza = load_and_prep_image(filename='03-pizza-dad.jpeg')\n","# Test our model on a custom image\n","pred_and_plot(model_7, \"03-pizza-dad.jpeg\", class_names)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1659464296157,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"apSfoTwbUYd1","outputId":"55bad668-9637-4681-c87c-2ddabadcad15"},"outputs":[],"source":["# Try my own image\n","pred_and_plot(model_7, \"drive/MyDrive/tensorflow_course/steak_custom.jpg\", class_names)"]},{"cell_type":"markdown","metadata":{"id":"77B-fEEJU5y8"},"source":["# Multi-class Image Classification\n","\n","1. Become one with the data\n","2. Preprocess the data (get it ready for a model)\n","3. Create a model (start with a baseline)\n","4. Fit the model (overfit it to make sure it works)\n","5. Evaluate the model\n","6. Adjust different hyperparameters and improve the model (try to beat baseline/reduce overfitting)\n","7. Repeat until satisfied"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6516,"status":"ok","timestamp":1659464302667,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"1bQQCT_yU_ki","outputId":"ad8da3da-06f0-42f7-9092-8decc6f06b43"},"outputs":[],"source":["import zipfile\n","!wget -nc --no-clobber https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n","\n","# Unzip our data\n","zip_ref = zipfile.ZipFile('10_food_classes_all_data.zip', 'r')\n","zip_ref.extractall()\n","zip_ref.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1659464302668,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"pdBcec-aWTB9","outputId":"2cbb2a5a-2931-4236-d859-47ecbfe5760c"},"outputs":[],"source":["import os\n","\n","# Walk through 10 classes of food image data\n","for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n","  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1659464302668,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Qx7bzs4rXMHH"},"outputs":[],"source":["# Setup the train and test directories\n","train_dir = '10_food_classes_all_data/train/'\n","test_dir = '10_food_classes_all_data/test/'"]},{"cell_type":"markdown","metadata":{"id":"VYmgejLRdqNE"},"source":["### Visualize"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1659464302668,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"1YPXE-zoXUHv","outputId":"5fafa4c8-a120-4134-c877-784738a9e08b"},"outputs":[],"source":["import pathlib\n","import numpy as np\n","data_dir = pathlib.Path(train_dir)\n","class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n","print(class_names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"elapsed":382,"status":"ok","timestamp":1659464303041,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"J4DzHbIjX3MC","outputId":"5d157105-60fc-413a-e858-59bef3eeacdf"},"outputs":[],"source":["# View an image\n","import random\n","img = view_random_image(target_dir=train_dir,\n","                        target_class=random.choice(class_names))"]},{"cell_type":"markdown","metadata":{"id":"oInCAo-bYTXL"},"source":["### Preprocess the data (prepare it for the model)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":376,"status":"ok","timestamp":1659464303415,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"fMfXs3KhZwCM","outputId":"7e6bc052-2dd9-4427-fd91-1eacafcf53fe"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Rescale\n","train_datagen = ImageDataGenerator(rescale=1/255.)\n","test_datagen = ImageDataGenerator(rescale=1/255.)\n","\n","# Load data in from directories and turn it into batches\n","train_data = train_datagen.flow_from_directory(train_dir,\n","                                               target_size=(224,224),\n","                                               batch_size=32,\n","                                               class_mode='categorical')\n","\n","test_data = test_datagen.flow_from_directory(test_dir,\n","                                             target_size=(224,224), \n","                                             batch_size=32,\n","                                             class_mode='categorical')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"413PqTBBaw13"},"source":["### Create a model (start with a baseline)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659464303415,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"0SpDc0jda2Dh"},"outputs":[],"source":["# Create a model w/ baseline (clone of cnn explainer)\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","model_8 = Sequential([\n","  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n","  Conv2D(10, 3, activation='relu'),\n","  MaxPool2D(),\n","  Conv2D(10, 3, activation='relu'),\n","  Conv2D(10, 3, activation='relu'),\n","  MaxPool2D(),\n","  Flatten(),\n","  Dense(10, activation='softmax') # changed to have 10 output neurons (10 classes) and use softmax activation function\n","])"]},{"cell_type":"markdown","metadata":{"id":"IzqMag0RdgIs"},"source":["### Compile the model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659464303415,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Wq3whfxPdhHP"},"outputs":[],"source":["# Compile the model\n","model_8.compile(loss='categorical_crossentropy',\n","                optimizer=Adam(),\n","                metrics=['accuracy'])\n"]},{"cell_type":"markdown","metadata":{"id":"DOXNGdv_ddt1"},"source":["### Fit the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269634,"status":"ok","timestamp":1659464573047,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"4SQSw3CYdcmD","outputId":"509cc307-1f8c-47de-98be-da28cb40e39a"},"outputs":[],"source":["# Fit the model\n","history_8 = model_8.fit(train_data, # now the augmented data is shuffled\n","                        epochs=5,\n","                        steps_per_epoch=len(train_data),\n","                        validation_data=test_data,\n","                        validation_steps=len(test_data))"]},{"cell_type":"markdown","metadata":{"id":"1YkaZJrLeox8"},"source":["### Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20653,"status":"ok","timestamp":1659464593697,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"18l5ahG4eq58","outputId":"db40d66e-a0b4-4932-9bd4-1e9323044d76"},"outputs":[],"source":["# Evaluate on the test data\n","model_8.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"elapsed":596,"status":"ok","timestamp":1659464594284,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"gKhvfkxBfRrL","outputId":"a86f0534-6d65-41ca-da1f-c79d758b1e2c"},"outputs":[],"source":["# check out the model's loss curves on the 10 classes\n","\n","def plot_loss_curves(history):\n","    \"\"\"\n","    Returns separate loss curves for training and validation metrics, takes history\n","    \"\"\" \n","    loss = history.history[\"loss\"]\n","    val_loss = history.history[\"val_loss\"]\n","\n","    accuracy = history.history[\"accuracy\"]\n","    val_accuracy = history.history[\"val_accuracy\"]\n","\n","    epochs = range(len(history.history[\"loss\"])) # How many epochs did we run for\n","    \n","    # Plot loss\n","    plt.plot(epochs, loss, label=\"training_loss\")\n","    plt.plot(epochs, val_loss, label=\"val_loss\")\n","    plt.title(\"loss\")\n","    plt.xlabel(\"epochs\")\n","    plt.legend()\n","\n","    # Plot accuracy\n","    plt.figure()\n","    plt.plot(epochs, accuracy, label=\"training_accuracy\")\n","    plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n","    plt.title(\"accuracy\")\n","    plt.xlabel(\"epochs\")\n","    plt.legend()\n","\n","plot_loss_curves(history_8)"]},{"cell_type":"markdown","metadata":{"id":"JTZq4-sXfuB4"},"source":["What do these loss curves tell us?\n","\n","Our model is **overfitting** the training set\n","It's getting great results on the training data but fails to generalize well to unseen data and performs poorly on the test dataset"]},{"cell_type":"markdown","metadata":{"id":"Xm1y7Ze-f_sO"},"source":["### Adjust model parameters\n","\n","Due to it's performance on the trainin data, it's clear our model is learning something but it's not generalizing well to unseen data.\n","\n","Let's try to fix overfitting by:\n","\n","* **Get more data** - Having more data gives a model more opportunity to learn diverse patterns\n","* **Simplify the model** - If the current model is overfitting the data, it may be too complicated of a model.  One way to simplify a model is to: reduce # of layers or reduce # of hidden units in layers\n","* **Use data augmentation** - Data augmentation manipulates the training data in such a way to add more diversity to it (without alterning the original data)\n","* **Use transfer learning** - Leverages the patterns another model has learned on similar data to your own and allows you to use those patterns on your own dataset.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659464594284,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"UHJx-EuUgBg2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":261524,"status":"ok","timestamp":1659464855806,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"kcupe5SZi8-W","outputId":"5218faca-7a10-49f3-b834-0c8153066ee7"},"outputs":[],"source":["# Try simplifying the model first\n","# Remove 2 convolutional layers from the model\n","model_9 = Sequential([\n","  Conv2D(10, 3, activation='relu', input_shape=(224, 224, 3)),\n","  MaxPool2D(),\n","  Conv2D(10, 3, activation='relu'),\n","  MaxPool2D(),\n","  Flatten(),\n","  Dense(10, activation='softmax') # changed to have 10 output neurons (10 classes) and use softmax activation function\n","])\n","model_9.compile(loss='categorical_crossentropy',\n","                optimizer=Adam(),\n","                metrics=['accuracy'])\n","\n","history_9 = model_9.fit(train_data, # now the augmented data is shuffled\n","                        epochs=5,\n","                        steps_per_epoch=len(train_data),\n","                        validation_data=test_data,\n","                        validation_steps=len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":174,"status":"ok","timestamp":1659464855966,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Ci3gGq3ji_I_","outputId":"6feca653-8bed-48d5-a290-1c997f46990b"},"outputs":[],"source":["model_8.summary(), model_9.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"elapsed":415,"status":"ok","timestamp":1659464856380,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"FXX2Ra2XjJvC","outputId":"599a33b1-a032-4f14-cb84-b2a693b2c51e"},"outputs":[],"source":["# Check out loss curves\n","plot_loss_curves(history_9)"]},{"cell_type":"markdown","metadata":{"id":"8zoVsWw8YwQD"},"source":["### Trying to reduce overfitting with data augmentation\n","\n","Ideally, we want to:\n","* Reduce overfitting (get the train and validation loss curves closer)\n","* Improve validation accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1659464856381,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"HybewuYCY7hd"},"outputs":[],"source":["# Create imageDataGenerator training instance with data augmentation\n","train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n","                                             rotation_range=0.2, # how much do you want to rotate an image\n","                                             zoom_range=0.2, # how much do you want to zoom?\n","                                             width_shift_range=0.2, # move image around on X axis\n","                                             height_shift_range=0.3, # move image around on Y axis\n","                                             horizontal_flip=True) # do you want to flip an image?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":225,"status":"ok","timestamp":1659464856603,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"147O2sLyZCkV","outputId":"7225c701-617c-4318-fdd4-de41532b4f15"},"outputs":[],"source":["# Import data and augment it from training directory\n","IMG_SIZE = (224, 224)\n","print(\"Augmented training data:\")\n","train_data_augmented = train_datagen_augmented.flow_from_directory(train_dir,\n","                                                                   target_size=IMG_SIZE,\n","                                                                   batch_size=32,\n","                                                                   class_mode=\"categorical\") # for demonstration purposes only, usually true\n","  "]},{"cell_type":"markdown","metadata":{"id":"1yJ76qlffHI4"},"source":["### Model Cloning"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":573770,"status":"ok","timestamp":1659465430372,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"zh-5tGOsZ4_d","outputId":"74697032-547f-45e3-f440-e82d328d2b68"},"outputs":[],"source":["# Create a model and fit with augmented data\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","# Clone model 8\n","model_10 = tf.keras.models.clone_model(model_8)\n","\n","# Compile the cloned model\n","model_10.compile(loss=\"categorical_crossentropy\",\n","                 optimizer=Adam(),\n","                 metrics=[\"accuracy\"])\n","\n","# Fit\n","history_10 = model_10.fit(\n","    train_data_augmented, \n","    epochs=5,\n","    steps_per_epoch=len(train_data_augmented),\n","    validation_data=test_data,\n","    validation_steps=len(test_data)\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11163,"status":"ok","timestamp":1659465441526,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"8mDevXEvhhBI","outputId":"c871888d-b5b5-49e2-b091-ddcb95421d7f"},"outputs":[],"source":["model_8.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11246,"status":"ok","timestamp":1659465452763,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"bCEHQgonhjbJ","outputId":"cc262dd3-2be7-42c8-a4da-c51eb00c94c9"},"outputs":[],"source":["model_10.evaluate(test_data)"]},{"cell_type":"markdown","metadata":{"id":"HERbxZR7qsR7"},"source":["### Repeat until satisfied\n","\n","Keep going, continually trying to bring our loss curves closer together and trying to improve the validatin/test accuracy.\n","\n","How?\n","\n","By running lots of experiments:\n","* Restructuring our model's architecture (increasing layers/hidden units)\n","* Adjust the learning rate\n","* Try different methods of data augmentation (adjust the hyperparameters in our ImageDataGenerator instance)\n","* Training for longer (e.g. 10 epochs instead of 5)\n","\n","* Transfer Learning: Take a model's pre-learned patterns from one problem and tweak them to suit your own problem.  For example, take a model trained on pictures of cars to recognize trucks."]},{"cell_type":"markdown","metadata":{"id":"-BL42tNFr5NY"},"source":["### Making a prediction with our trained model\n","\n","Let's use our trained model to make some predictions on our own custom images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1659465452764,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"-tm-gWkKsGZd","outputId":"e54147e2-767d-4256-f483-0830f06747fd"},"outputs":[],"source":["# Reminder for classes\n","class_names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":557,"status":"ok","timestamp":1659465453475,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"MUGPDDyJsK0N","outputId":"608897d2-d85f-4abd-daa0-e8b1408d11d5"},"outputs":[],"source":["# Download some custom images\n","\n","!wget -nc --no-clobber https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-hamburger.jpeg\n","!wget -nc --no-clobber https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-pizza-dad.jpeg\n","!wget -nc --no-clobber https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-steak.jpeg\n","!wget -nc --no-clobber https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/03-sushi.jpeg"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1659465453475,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"ioIMvj2gtyXt"},"outputs":[],"source":["# Remake pred_and_plot to take multiclass\n","def pred_and_plot(model, filename, class_names):\n","  \"\"\"\n","  Imports an image located at filename, makes a prediction on it with\n","  a trained model and plots the image with the predicted class as the title.\n","  \"\"\"\n","  # Import the target image and preprocess it\n","  img = load_and_prep_image(filename)\n","\n","  # Make a prediction\n","  pred = model.predict(tf.expand_dims(img, axis=0))\n","  # Multiclass logic and get the predicted class\n","  if len(pred[0]) > 1:\n","    pred_class = class_names[tf.argmax(pred[0])]\n","  else:\n","    pred_class = class_names[int(tf.round(pred)[0][0])]\n","\n","  # Plot the image and predicted class\n","  plt.imshow(img)\n","  plt.title(f\"Prediction: {pred_class}\")\n","  plt.axis(False);\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"executionInfo":{"elapsed":914,"status":"ok","timestamp":1659468223621,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"8p01EhNztH7a","outputId":"89fd4997-457d-4872-c5da-ef7c06b51436"},"outputs":[],"source":["# Make a prediction using model_10\n","pred_and_plot(model=model_10, \n","              filename=\"03-hamburger.jpeg\", \n","              class_names=class_names)"]},{"cell_type":"markdown","metadata":{"id":"Epc5uklVv2mO"},"source":["### Saving and loading our trained model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2260,"status":"ok","timestamp":1659468259568,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"XcGMlI29A8ZE","outputId":"781994ec-1bb4-412a-c3ba-444fda10b896"},"outputs":[],"source":["# Save a model\n","model_10.save('saved_trained_model_10')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13497,"status":"ok","timestamp":1659468324119,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"7gLay1RvBENx","outputId":"09d9112f-a1e0-4840-981d-97ae2e2509c9"},"outputs":[],"source":["# Load in a trained model and evaluate it\n","loaded_model_10 = tf.keras.models.load_model('saved_trained_model_10')\n","loaded_model_10.evaluate(test_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11711,"status":"ok","timestamp":1659468635110,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Z8CyL66VBSl9","outputId":"2c9723e6-bf85-46db-9b0b-eaf45293c139"},"outputs":[],"source":["# Compare our loaded model to our existing model\n","model_10.evaluate(test_data)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPZepntWX2IokNWhvE+Vea4","collapsed_sections":[],"mount_file_id":"1LvRGrjhRLlQfeDx_MS-vLHSuqDgnwtVk","name":"03_convolutional_neural_networks_and_computer_vision.ipynb","provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.9.12 64-bit ('miniconda3')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.12"},"vscode":{"interpreter":{"hash":"215bc93be91779c90c22d9452977b07e46a2652f59eedc500a409df416ed83eb"}}},"nbformat":4,"nbformat_minor":0}
