{"cells":[{"cell_type":"markdown","metadata":{"id":"1N8tO8eBY01x"},"source":["# What we're going to cover\n","\n","\n","\n","*   Architecture of a neural network regression model\n","*   Input & output shapes of a regression model (features and labels/dependendent/independent variables)\n","*   Creating custom data to view and fit\n","*   Steps in modelling\n","    *   Creating, compiling, fitting, evaluating models\n","* Different evaluation methods\n","*   Saving and loading models\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"SBCyE7yTZ6hr"},"source":["## Regression Inputs and Outputs\n","Predicting sale price of a house\n","\n","**Inputs:** predictors, covariates, features\n","  *   Number of bedrooms\n","  *   Bathrooms\n","  *   Garage space\n","\n","**Outputs:**\n","  *   Sale Price\n","\n","**Numerical Encoding**\n","  *   e.g. 1-hot encoding\n","\n","## Input & output shapes\n","\n","The number of input features = shape\n","\n","[bedroom, bathroom, garage]\n","\n","shape = [3]\n","\n","## Typical architecture of a classification neural network \n","\n","The word *typical* is on purpose.\n","\n","Because the architecture of a classification neural network can widely vary depending on the problem you're working on.\n","\n","However, there are some fundamentals all deep neural networks contain:\n","* An input layer.\n","* Some hidden layers.\n","* An output layer.\n","\n","Much of the rest is up to the data analyst creating the model.\n","\n","The following are some standard values you'll often use in your classification neural networks.\n","\n","| **Hyperparameter** | **Binary Classification** | **Multiclass classification** |\n","| --- | --- | --- |\n","| Input layer shape | Same as number of features (e.g. 5 for age, sex, height, weight, smoking status in heart disease prediction) | Same as binary classification |\n","| Hidden layer(s) | Problem specific, minimum = 1, maximum = unlimited | Same as binary classification |\n","| Neurons per hidden layer | Problem specific, generally 10 to 100 | Same as binary classification |\n","| Output layer shape | 1 (one class or the other) | 1 per class (e.g. 3 for food, person or dog photo) |\n","| Hidden activation | Usually [ReLU](https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning) (rectified linear unit) | Same as binary classification |\n","| Output activation | [Sigmoid](https://en.wikipedia.org/wiki/Sigmoid_function) | [Softmax](https://en.wikipedia.org/wiki/Softmax_function) |\n","| Loss function | [Cross entropy](https://en.wikipedia.org/wiki/Cross_entropy#Cross-entropy_loss_function_and_logistic_regression) ([`tf.keras.losses.BinaryCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy) in TensorFlow) | Cross entropy ([`tf.keras.losses.CategoricalCrossentropy`](https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy) in TensorFlow) |\n","| Optimizer | [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) (stochastic gradient descent), [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) | Same as binary classification |\n","\n","***Table 1:*** *Typical architecture of a classification network.* ***Source:*** *Adapted from page 295 of [Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow Book by Aurélien Géron](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)*\n","\n","Don't worry if not much of the above makes sense right now, we'll get plenty of experience as we go through this notebook.\n","\n","Let's start by importing TensorFlow as the common alias `tf`. For this notebook, make sure you're using version 2.x+."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7076,"status":"ok","timestamp":1658332867100,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"vMzTJvJDcnKt","outputId":"851dff96-121f-47c9-a9cc-79829c5cb396"},"outputs":[],"source":["import tensorflow as tf\n","print(tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"HgVbUiqSdYig"},"source":["# Introduction to Regression with NEural Netowrks in TensorFlow\n","\n","There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables.\n","\n","Predicting a number\n","\n","# Creating data to view and fit"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"executionInfo":{"elapsed":394,"status":"ok","timestamp":1658332867491,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"YJFq6qBaeiIt","outputId":"0e36631a-43a6-41ea-e974-475d13016d2d"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Create features\n","X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n","\n","# Create labels\n","y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n","\n","# Visualize it\n","plt.scatter(X, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":317,"status":"ok","timestamp":1658332867804,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"-jznoGY_friV","outputId":"d4177d95-769b-4480-f5ef-14d94e430497"},"outputs":[],"source":["y == X + 10"]},{"cell_type":"markdown","metadata":{"id":"tEKRHHKyfwFo"},"source":["### Input and Output Shapes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1658332867804,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"y9-NbL92fzey","outputId":"b9723e4a-a528-4042-a359-fbe19560b523"},"outputs":[],"source":["# Create a demo tensor for our housing price prediction problem\n","house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n","house_price = tf.constant([939700])\n","house_info, house_price"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210,"status":"ok","timestamp":1658332868011,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"1WqgGeCCgeHQ","outputId":"b3a6b692-b06b-442f-ee58-260528dcc1ca"},"outputs":[],"source":["input_shape = X[0].shape\n","output_shape = y[0].shape\n","input_shape, output_shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1658332868011,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"vc8F4jzPhQO0","outputId":"1fca93fd-a366-4fe3-d0bd-bb8d272592e0"},"outputs":[],"source":["# Turn our NumPy arrays into tensors\n","X = tf.cast(tf.constant(X), dtype=tf.float32)\n","y = tf.cast(tf.constant(y), dtype=tf.float32)\n","X, y\n","\n","## OLD\n","# Fit the model\n","# model.fit(X, y, epochs=5) # this will break with TensorFlow 2.7.0+\n"," \n","## New\n","# Fit the model\n","# model.fit(tf.expand_dims(X, axis=-1), y, epochs=5) # <- updated line"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658332868011,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"K0rBEdVqh2FJ","outputId":"a7cdbba8-0867-4a9e-cac5-ce14b97f8ac7"},"outputs":[],"source":["input_shape = X[0].shape\n","output_shape = y[0].shape\n","input_shape, output_shape"]},{"cell_type":"markdown","metadata":{"id":"qv28-gW4iA4_"},"source":["### Steps in modelling with TensorFlow\n","\n","1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n","2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to imporve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n","3. **Fitting a model** - letting the model try to find patterns between X & y (features and labels)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAGwvWZvlmn1"},"outputs":[],"source":["# Optionally, the first layer can receive an 'input_shape' argument:\n","# model = tf.keras.Sequential()\n","# model.add(tf.keras.layers.Dense(8, input_shape=(16,)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1424,"status":"ok","timestamp":1658332869433,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"2qXrs9JXir4-","outputId":"f53fdf64-f225-44d1-a1d8-fbca25cf50ec"},"outputs":[],"source":["# Set random seed\n","tf.random.set_seed(42)\n","\n","# 1. Create a model using the Sequential API\n","model = tf.keras.Sequential(\n","    [tf.keras.layers.Dense(1)]\n","    )\n","# 2. Compile the model\n","model.compile(\n","    loss=tf.keras.losses.mae, # mae is short for mean absolute error\n","    optimizer=tf.keras.optimizers.SGD(), # sgd is short for stochastic gradient descent\n","    metrics=[\"mae\"]\n","              )\n","# 3. Fit the model\n","model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)\n","print('trained')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1658332869434,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"9orZ33ohnNLe","outputId":"8eb4801d-2913-4827-9fdb-464a1bbe3085"},"outputs":[],"source":["# Check out values for X and y\n","X, y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1658332869544,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Nn9MjOfjnQ9s","outputId":"b7528cc9-6670-4f8d-b31a-e54eb8c81d4b"},"outputs":[],"source":["# Try and make a prediction\n","\n","y_pred = model.predict([17.0])\n","y_pred"]},{"cell_type":"markdown","metadata":{"id":"9qy1lAJ9ntBW"},"source":["## Improving our model\n","\n","We can improve our model by altering the steps we took to create the model\n","\n","1. **Creating a model** - we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n","2.  **Compiling a model** - we might change the optimization function or perhaps the **learning rate** of the optimization function.\n","3. **Fitting a model** - we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBnQIFhrpMwY"},"outputs":[],"source":["# Let's rebuild our model\n","\n","# 1. Create a model using the Sequential API\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(1)\n","])\n","# 2. Compile the model\n","model.compile(loss=tf.keras.losses.mae,\n","              optimizer=tf.keras.optimizers.SGD(),\n","              metrics=[\"mae\"]\n","              )\n","              \n","# 3. Fit the model\n","model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)\n","print('trained')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1658332871573,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"D4gG8Abss0bU","outputId":"235bddad-3577-48c4-d5cf-dfd467431220"},"outputs":[],"source":["# Let's see if our models prediction has improved...\n","model.predict([17.0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"920X-hNRtIu9"},"outputs":[],"source":["# Write a model by yourself by changing 1 thing from the previous model\n","\n","# 1. Create the model\n","model = tf.keras.Sequential([\n","                             tf.keras.layers.Dense(50, activation=None),\n","                             tf.keras.layers.Dense(1)\n","                             ])\n","\n","# 2. Compile the model\n","model.compile(loss=\"mae\",\n","              optimizer=tf.keras.optimizers.Adam(lr=0.1),\n","              metrics=[\"mae\"]\n","              )\n","              \n","# 3. Fit the model\n","model.fit(tf.expand_dims(X, axis=-1), y, epochs=66)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":135,"status":"ok","timestamp":1658332873535,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"deTxymiRuOG3","outputId":"b0d3fb23-799f-4341-b646-95d650e5cc2b"},"outputs":[],"source":["model.predict([17.0])"]},{"cell_type":"markdown","metadata":{"id":"8zCbL5O_1DnV"},"source":["## Evaluating a model\n","\n","In practice, a typical workflow you'll go through when building a neural network is:\n","\n","```\n","Build a model > fit it > evaluate it > tweak a model > repeat...\n","```\n","\n","When it comes to evaluation... there are 3 words you should memorize:\n","> \"Visualize, visualize, visualize\"\n","\n","## Vizualize:\n","* **The data** - What data are we woring with and what does it look like?\n","* **The model** - What does our model look like?\n","* **Training the model** - How does a model perform while it learns?\n","* **Predictions** - How do the predictions of a model line up against the ground truth (the original labels)?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1658332873536,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"TA6FWgni19ua","outputId":"e434e162-18d3-4308-a0d6-01ca1aa394d1"},"outputs":[],"source":["# Make a bigger dataset\n","\n","X = tf.range(-100, 100, 4)\n","X"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1658332873536,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"ZPDuMgnk2J70","outputId":"863ee4e5-c3c9-454e-b89b-afab8e27c027"},"outputs":[],"source":["# Make labels for the dataset\n","y = X + 10\n","y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":252,"status":"ok","timestamp":1658332873785,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"-8990Pnh2RQb","outputId":"40f090a0-b5ab-4f9f-d45d-cb1d1626d884"},"outputs":[],"source":["# Visualize the data\n","import matplotlib.pyplot as plt\n","\n","plt.scatter(X, y)"]},{"cell_type":"markdown","metadata":{"id":"eblINcG72gub"},"source":["### The 3 Sets\n","\n","* Training set - the model learns from this data, which is typically 70-80% of the total data you have available.\n","* Validation set - the model gets tuned on this data, 10-15%\n","* Test set - the model gets evaluated on this data to test what it has learned, 10-15%"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1658332873786,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"GoKtMmCr3iQj","outputId":"34171b26-fc17-4dcd-982e-c2ebd7d8db4f"},"outputs":[],"source":["X_train = X[:40]\n","y_train = y[:40]\n","X_test = X[40:]\n","y_test = y[40:]\n","\n","X_train, y_train, X_test, y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"elapsed":768,"status":"ok","timestamp":1658332874552,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"E8NU1Wy-4rDM","outputId":"0d2e313e-b3ed-4289-d7c5-28424163a460"},"outputs":[],"source":["### Visualizing the data\n","\n","plt.figure(figsize=(10, 7))\n","# plot training in blue\n","plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n","# plot testing in red\n","plt.scatter(X_test, y_test, c=\"r\", label=\"Testing data\")\n","# show a legend\n","plt.legend()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QmeKD32-52mq"},"outputs":[],"source":["# Lets build a network for our data\n","# 1. Create a model\n","tf.random.set_seed(42)\n","model = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\"),\n","     tf.keras.layers.Dense(1, name=\"output_layer\"), \n","    ], name=\"model_1\"\n",")\n","\n","# 2. Compile the model\n","model.compile(loss=\"mae\", optimizer=\"sgd\", metrics=[\"mae\"])\n","\n","# 3. Fit the model\n","model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":298,"status":"ok","timestamp":1658332876722,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"poEp7t4z7XB5","outputId":"493ce928-6f2f-42dc-a94b-9307a988b35f"},"outputs":[],"source":["### Visualizing the model\n","# model.build()\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"FMhWlanJYJ98"},"source":["* Total params - total number of parameters in the model.\n","* Trainable parameters - these are the parameters (patterns) the model can update as it trains.\n","* Non-trainable params - these parameters aren't updated during the training (this is typical when you bring in already learned patterns or parameters from other models during **transfer learning**)\n","\n","📖 **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video.\n","\n","🔧 **Exercise:** Try playing around with the number of hidden units in the dense layer, see how that effects the number of parameters (total and trainable) by callling `model.summary()`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UIlnZLsQYbAm"},"outputs":[],"source":["# Let's fit our model to the training data\n","# model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1658332876722,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"czy-VHtDaU0r","outputId":"92fc3501-273a-4f96-edc3-c9ecd509922e"},"outputs":[],"source":["# Get a summary of our model\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1658332876722,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"3LIVsJjiatAl","outputId":"6180f45f-ed36-4404-a4ca-1e1c535d0b3e"},"outputs":[],"source":["from tensorflow.keras.utils import plot_model\n","plot_model(model=model, show_shapes=True)"]},{"cell_type":"markdown","metadata":{"id":"xOG4XicZdC7V"},"source":["### Visualizing model predictions\n","\n","To visualize predictions, it's a good idea to plot them against the ground truth labels.\n","\n","Often you'll see this in the form of y_test or y_true vs y_pred (ground truth vs your model's predictions)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1658332876723,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"K5J4w6N2dGqd","outputId":"179c369d-dde3-4b85-8c57-c54f0c61854e"},"outputs":[],"source":["# Make some predictions\n","y_pred = model.predict(X_test)\n","y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658332876723,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"HKQYIUMjdudB","outputId":"b11b6493-3e80-48d2-e683-5678f1c3e025"},"outputs":[],"source":["y_test"]},{"cell_type":"markdown","metadata":{"id":"3Dh8u0JHd30K"},"source":["# Let's create a plotting function"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":428},"executionInfo":{"elapsed":358,"status":"ok","timestamp":1658332877077,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"KRtgymuweJmv","outputId":"9be9cedb-f268-4bcb-cbc6-c3e75fdfe280"},"outputs":[],"source":["def plot_predictions(train_data=X_train,\n","                     train_labels=y_train,\n","                     test_data=X_test,\n","                     test_labels=y_test,\n","                     predictions=y_pred):\n","  \"\"\"\n","  Plots training data, test data and compares predictions to ground truth labels.\n","  \"\"\"\n","  plt.figure(figsize=(10, 7))\n","  # plot training in blue\n","  plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n","  # plot testing in yellow\n","  plt.scatter(test_data, test_labels, c=\"y\", label=\"Testing data\")\n","  # plot predictions in red\n","  plt.scatter(test_data, predictions, c=\"r\", label=\"Predictions\")\n","  # show a legend\n","  plt.legend()\n","\n","plot_predictions()\n"]},{"cell_type":"markdown","metadata":{"id":"m43T-cQ8fiv7"},"source":["### Evaluating our model's predictions with regression evaluation metrics\n","\n","Depending on the problem you're working on, there will be different evaluation metrics to evaluate your model's performance.\n","\n","Since we're working on a regression, two of the main metrics:\n","* MAE - mean absolute error, \"on average, how wrong is each of my model's predictions\"\n","* MSE - mean square error, \"square the average errors\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1658332877332,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"drcVFeUZfrE0","outputId":"5205e73e-462b-41e1-d9fc-5b6cee7915c1"},"outputs":[],"source":["# Evaluate the model on the test set\n","model.evaluate(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1658332877333,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"NHSIchpghyik","outputId":"35259d51-689e-4f48-b61c-7317eed024f6"},"outputs":[],"source":["# Calculate the mean absolute error\n","print(tf.shape(y_pred), tf.shape(y_test))\n","mae = tf.keras.metrics.MeanAbsoluteError()\n","mae.reset_state()\n","mae.update_state(y_test, tf.squeeze(y_pred))\n","mae.result().numpy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122,"status":"ok","timestamp":1658332877451,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"jy6e6ke7kWzm","outputId":"50fb2478-2a6a-45b9-c3aa-caa37a5dad1b"},"outputs":[],"source":["# Calculate the mean square error\n","mse = tf.keras.metrics.MeanSquaredError()\n","mse.reset_state()\n","mse.update_state(y_test, tf.squeeze(y_pred))\n","mse.result().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1658332877451,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Gi759o7qvATw","outputId":"e812b306-2945-48a3-ea7d-5741e27a015f"},"outputs":[],"source":["# Make some functions to reuse mae and mse (not necessary)\n","def mae(y_true, y_pred):\n","  mae = tf.keras.metrics.MeanAbsoluteError()\n","  mae.reset_state()\n","  mae.update_state(y_true, tf.squeeze(y_pred))\n","  return mae.result().numpy()\n","\n","def mse(y_true, y_pred):\n","  mse = tf.keras.metrics.MeanSquaredError()\n","  mse.reset_state()\n","  mse.update_state(y_true, tf.squeeze(y_pred))\n","  return mse.result().numpy()\n","\n","mae(y_test, y_pred), mse(y_test, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"BDQmHI_EvwuU"},"source":["### Running experiments to improve our model\n","\n","```\n","Build :> Fit > Eval. > Tweak > repeat\n","```\n","\"Experiment, Experiment, Experiment\"\n","\n","1. Get more data - get more examples for your model to train on (more opportunities to learn patterns or relationships between features and labels).\n","\n","2. Make your model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n","\n","3. Train for longer - give your model more of a chance to find patterns in the data.\n","\n","\n","3 Modeling Experiments\n","\n","1. `model_1` - same as original model, 1 layer, trained for 100 epochs\n","2. `model_2` - 2 layers, trained for 100 epochs\n","3. `model_3` - 2 layers, trained for 500 epochs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ByZooxvD5CRy"},"outputs":[],"source":["# 1. model_1\n","tf.random.set_seed(42)\n","model_1 = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(1),\n","    ], name=\"model_1\"\n",")\n","\n","# 2. Compile the model\n","model_1.compile(loss=\"mae\", optimizer=\"sgd\", metrics=[\"mae\"])\n","\n","# 3. Fit the model\n","model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"executionInfo":{"elapsed":145,"status":"ok","timestamp":1658332880878,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"XHtnJeX16Bbi","outputId":"faa47dca-2818-4191-c8f5-0c492b33ee38"},"outputs":[],"source":["# Make and plot predictions for model_1\n","y_preds_1 = model_1.predict(X_test)\n","plot_predictions(predictions=y_preds_1)\n","mae_1 = mae(y_test, y_preds_1)\n","mse_1 = mse(y_test, y_preds_1)\n","mae_1, mse_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWJMCgrD7fJj"},"outputs":[],"source":["# 1. Build model_2\n","tf.random.set_seed(42)\n","model_2 = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(10),\n","     tf.keras.layers.Dense(1),\n","    ], name=\"model_2\"\n",")\n","\n","# 2. Compile the model\n","model_2.compile(loss=\"mae\", optimizer=\"sgd\", metrics=[\"mae\", \"mse\"])\n","\n","# 3. Fit the model\n","model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":483},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1658332883598,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"qQ0gXISf7uE8","outputId":"9d479cf2-eb3a-4460-c424-770a5d887d64"},"outputs":[],"source":["y_preds_2 = model_2.predict(X_test)\n","plot_predictions(predictions=y_preds_2)\n","mae_2 = mae(y_test, y_preds_2)\n","mse_2 = mse(y_test, y_preds_2)\n","mae_2, mse_2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AwGEKN-Z8yL5"},"outputs":[],"source":["# 1. Build model_3\n","tf.random.set_seed(42)\n","model_3 = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(10),\n","     tf.keras.layers.Dense(1),\n","    ], name=\"model_3\"\n",")\n","\n","# 2. Compile the model\n","model_3.compile(loss=\"mae\", optimizer=\"sgd\", metrics=[\"mae\", \"mse\"])\n","\n","# 3. Fit the model\n","model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1658332896562,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"tBqPGKZ388eb","outputId":"57d26e38-2f10-433d-a6df-ae3ef63e2653"},"outputs":[],"source":["y_preds_3 = model_3.predict(X_test)\n","plot_predictions(predictions=y_preds_3)\n","mae_3 = mae(y_test, y_preds_3)\n","mse_3 = mse(y_test, y_preds_3)\n","mae_3, mse_3"]},{"cell_type":"markdown","metadata":{"id":"_j8MrxHxFDNZ"},"source":["### Comparing Results\n","\n","🔑 **Note:** You want to start with small experiments (small models) and make sure they work and then increase their scale when necessary.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1658332896562,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"QkM1T0K8Fmg-","outputId":"ceb03386-3cd7-4cba-85a1-dbb3e5ed8f0c"},"outputs":[],"source":["# Compare model results using pandas DataFrame\n","import pandas as pd\n","\n","model_results = [[\"model_1\", mae_1, mse_1],[\"model_2\", mae_2, mse_2],[\"model_3\", mae_3, mse_3]]\n","all_results = pd.DataFrame(model_results, columns=[\"model\", \"mae\", \"mse\"])\n","all_results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1658332896563,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"ccUGNJneGMQW","outputId":"3e5dcda1-23fa-4dfb-e639-5c5af28dee50"},"outputs":[],"source":["print(model_1.summary(), \"\\n\\n\", model_2.summary(), \"\\n\\n\", model_3.summary())"]},{"cell_type":"markdown","metadata":{"id":"EmWkCT0wGZqw"},"source":["**Note:** One of the main goals should be to minimize the time between your experiments. The more experiments you do, the more things you'll figure out which don't work and in turn, get closer to figuring out what does work.\n","\n","Machine learning practitioner's motto: \"*Experiment, Experiment, Experiment*\"\n","\n","One really good habit in ML modelling is to track the results of your experiments.\n","\n","When doing so, it can be tedious if you're running lots of experiments.\n","\n","Luckily, there are tools to help.\n","\n","**Resource:** As you build more models, you'll want to look into using\"\n","\n","* [**TensorBoard**](https://www.tensorflow.org/tensorboard) - a component of the TensorFlow library to help track modelling experiments\n","* [**Weights & Biases**](https://wandb.ai/site) - a tool for tracking all kinds of ML experiments (plugs straight into TensorBoard)\n"]},{"cell_type":"markdown","metadata":{"id":"9NzM7IQAH5Dm"},"source":["### Saving our Models\n","\n","Allows us to use them outside of Google Colab (or wherever they were trained) such as in a web or mobile app."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1658332896563,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"VNjqDCS2H6bO","outputId":"e41a23e8-8c22-4dc1-f6a9-aad3838c6516"},"outputs":[],"source":["# Save using hdf5 format\n","model_1.save('model_1.h5')\n","model_2.save('model_2.h5')\n","model_3.save('model_3.h5')\n","\n","# Load\n","loaded_model_1 = tf.keras.models.load_model('model_1.h5')\n","loaded_model_2 = tf.keras.models.load_model('model_2.h5')\n","loaded_model_3 = tf.keras.models.load_model('model_3.h5')\n","\n","# Compare model predictions with saved predictions\n","model_2_preds = model_2.predict(X_test)\n","loaded_2_preds = loaded_model_2.predict(X_test)\n","model_2_preds == loaded_2_preds"]},{"cell_type":"markdown","metadata":{"id":"Jk9MlUEtVmlE"},"source":["## Download a model (or any other file) from Google Colab\n","\n","If you want to dl your files from Google Colab:\n","\n","1. You can go to the \"files\" tab and right click on the file you're after and click \"download\"\n","\n","2. Use code (see cell below)\n","\n","3. Save it to Google Drive by connecting and copying it"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":116,"status":"ok","timestamp":1658332977241,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"O1yJlTFkV-FF","outputId":"b3c73d38-83b7-4268-f000-a6894a14e4d7"},"outputs":[],"source":["# Download via code\n","from google.colab import files\n","# files.download(\"/content/model_3.h5\")\n","\n","# files.download(\"/content/model_2.h5\")\n","\n","# files.download(\"/content/model_1.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uXvUdIvrWh6p"},"outputs":[],"source":["# First mnt google drive connection\n","# Save a file from Colab to Drive \n","# !cp /content/model_1.h5 /content/drive/MyDrive/tensorflow_course"]},{"cell_type":"markdown","metadata":{"id":"EEzpiSUHXjhp"},"source":["# A Larger Example"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5852,"status":"ok","timestamp":1658335995324,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"gzuHesoYXmlY"},"outputs":[],"source":["# Import required libs\n","import tensorflow as tf\n","import pandas as pd\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":522,"status":"ok","timestamp":1658335996802,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"JuvS1H6gYl87","outputId":"0bcb355a-edd5-4ce7-ccad-e558051ec270"},"outputs":[],"source":["# Read in the insurance dataset\n","insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n","insurance[:10]"]},{"cell_type":"markdown","metadata":{"id":"CKc1kSffZDW2"},"source":["Dependent variables: charges\n","Independent variables: age, sex, bmi, children, smoker, region"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1658335998840,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"1VRKFJfyZKUm","outputId":"2c2f7c6f-e773-4a0f-9d98-4f6e17c3049b"},"outputs":[],"source":["# pd.get_dummies automcatically one_hot encodes appropriate columns\n","insurance_one_hot = pd.get_dummies(insurance)\n","insurance_one_hot.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":152,"status":"ok","timestamp":1658336000394,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"vBK8AfKpavF4","outputId":"f39a6169-16c0-4da1-dbf7-953e7184b89c"},"outputs":[],"source":["# Create X and y values (features and labels)\n","X = insurance_one_hot.drop(\"charges\", axis=1)\n","y = insurance_one_hot[\"charges\"]\n","X.head(), y.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":492,"status":"ok","timestamp":1658336003434,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"lBQNifxKbYFi","outputId":"903e56c8-bff6-4acb-c765-a2f4e3d832b8"},"outputs":[],"source":["# Create training and test sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","len(X), len(X_train), len(X_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8fLyD8e9bZLM"},"outputs":[],"source":["# Build a neural network (sort of like model_2 above)\n","tf.random.set_seed(42)\n","# Create a model\n","insurance_model = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(10),\n","     tf.keras.layers.Dense(1)\n","    ]\n",")\n","# Compile\n","insurance_model.compile(loss=\"mae\", optimizer=\"sgd\", metrics=[\"mae\"])\n","\n","# Fit the model\n","insurance_model.fit(X_train, y_train, epochs=100)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":300,"status":"ok","timestamp":1658335140181,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"mIAJY1mqePpG","outputId":"7a571b90-75fa-47fd-a1c7-f9da742d9125"},"outputs":[],"source":["# Evaluate results of insurance model on test data\n","insurance_model.evaluate(X_test, y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1658335185260,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"DG3_IPDCeqK_","outputId":"72e4ed90-bfe0-4098-d448-ccc28e8a9874"},"outputs":[],"source":["y_train.median(), y_train.mean()"]},{"cell_type":"markdown","metadata":{"id":"-4535CLlf5wa"},"source":["## Right now it looks like our model isn't performing too well...l let's try to improve it"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9810,"status":"ok","timestamp":1658338869908,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"zi8Ay79xgDHG"},"outputs":[],"source":["tf.random.set_seed(42)\n","insurance_model_adam = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(100),\n","     tf.keras.layers.Dense(10),\n","     tf.keras.layers.Dense(1)\n","    ]\n",")\n","# insurance_model_nadam = tf.keras.Sequential(\n","#     [\n","#      tf.keras.layers.Dense(100),\n","#      tf.keras.layers.Dense(10),\n","#      tf.keras.layers.Dense(1)\n","#     ]\n","# )\n","# Compile\n","insurance_model_adam.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n","# insurance_model_nadam.compile(loss=\"mae\", optimizer=\"nadam\", metrics=[\"mae\", \"mse\"])\n","# Fit the model\n","history_adam = insurance_model_adam.fit(X_train, y_train, epochs=200, verbose=0)\n","# history_nadam = insurance_model_nadam.fit(X_train, y_train, epochs=200, verbose=0)\n","# Evaluate results of insurance model on test data\n","# insurance_model_adam.evaluate(X_test, y_test)"]},{"cell_type":"markdown","metadata":{"id":"vtC_igYTkd8c"},"source":["# What are Optimizers?\n","Optimizers define how neural networks learn\n","\n","They find the values of paramaters such that a loss function is at it's lowest.\n","\n","**Types**\n","\n","**Gradient Descent (GD):** Takes small steps iteratively until we reach the correct weights.  The weight is only updated once after seeing the entire dataset.\n","\n","**Stochastic Gradient Descent (SGD):** Updates weights after seeing each datapoint instead of the whole dataset.  This makes very noisy jumps that can go away from the optimal value.\n","\n","**Mini-Batch Gradient Descent (MBGD):** Updates weights after a few sample datapoints instead of individual.\n","\n","**SGD + Momentum:** Ignores datapoints that don't follow the momentum of other datapoints.  Can learn faster but can also overshoot.\n","\n","**SGD + Momentum + Acceleration:** When unusual datapoints occur, the model deccelerates and readjusts so it doesn't overshoot.  Using multiple parameters is not ideal as the learning rate is fixed across the board.\n","\n","**Adaptive Gradient Algorithm (AdaGrad):** Gradient-based optimization. The learning rate is adapted component-wise to the parameters by incorporating knowledge of past observations. As iterations go on, the learning rate is decreased\n","\n","**AdaDelta:** A more robust extension of Adagrad that adapts learning rates based on a moving window of gradient updates, instead of accumulating all past gradients. This way, Adadelta continues learning even when many updates have been done.\n","\n","**Adam:** AdaDelta + expected value of past gradients (momentum).  Slow initially, but pick up speed over time.\n","\n","**NAdam:** Adam + acceleration.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1658338875940,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"2usE-muepZf9","outputId":"368069ff-7100-4dee-f288-ef7d8dc03a14"},"outputs":[],"source":["# plot history (also known as a loss curve or training curve)\n","pd.DataFrame(history_adam.history).plot()\n","# pd.DataFrame(history_nadam.history).plot()\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epochs\")\n"]},{"cell_type":"markdown","metadata":{"id":"HTnoQAj7qsrI"},"source":["# Early Stopping\n","**Question:** How long should you train for?\n","\n","It depends on the problem you're working on.  TensorFlow as created a solution called EarlyStopping Callback.\n","\n","It is a TensorFlow component you can add to your model to stop training once it stops improving a certain metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y3ed4R7grz4K"},"outputs":[],"source":["callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n","tf.random.set_seed(42)\n","insurance_model_early_stopping = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(100),\n","     tf.keras.layers.Dense(10),\n","     tf.keras.layers.Dense(1)\n","    ]\n",")\n","# Compile\n","insurance_model_early_stopping.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n","# Fit the model\n","history_early_stopping = insurance_model_early_stopping.fit(X_train, y_train, epochs=200, callbacks=[callback])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":296},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1658338851487,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"-jFxAf63sHgJ","outputId":"834c8808-38d2-4fe7-abb5-0088a316d5ac"},"outputs":[],"source":["# plot history (also known as a loss curve or training curve)\n","pd.DataFrame(history_early_stopping.history).plot()\n","# pd.DataFrame(history_nadam.history).plot()\n","plt.ylabel(\"loss\")\n","plt.xlabel(\"epochs\")\n"]},{"cell_type":"markdown","metadata":{"id":"MSfu2wXHsZ2R"},"source":["# Preprocessing data (normalization and standardization)\n","\n","The goal is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the range of values. \n","\n","Many ML algos perform better or converge faster when features are on a relatively similar scale and/or close to normally distributed.\n","\n","**Example Algorithm Families:**\n","* Linear and logistic regression\n","* Nearest neighbors\n","* Neural networks\n","* Support vector machines with radial bias kernel functions\n","* Principal components analysis\n","* Linear discriminant analysis\n","\n","In terms of scaling values, neural networks tend to prefer normalization.\n","\n","If you're not sure on which to use, you could try both and see which performs better."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1658342892917,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"WtzSKXVy0vCK","outputId":"1a24206c-d4ba-4f38-f945-b97ad3aa941d"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","\n","# Read in insurance df\n","insurance = pd.read_csv('https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv')\n","insurance"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1658339091755,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"ywmYC8TOtdg6","outputId":"dbc0412e-05c1-4cd2-9f18-1c20529ea74c"},"outputs":[],"source":["X[\"age\"].plot(kind=\"hist\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"elapsed":579,"status":"ok","timestamp":1658339123926,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Sq9zNI8Dtpgm","outputId":"cb64ccd0-e95d-4c9c-ca46-fbf02c43878e"},"outputs":[],"source":["X[\"bmi\"].plot(kind=\"hist\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1658339164788,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"JobTeN-Ptu_s","outputId":"dd13e781-862e-40ae-892d-fb5725256b80"},"outputs":[],"source":["X[\"children\"].value_counts()"]},{"cell_type":"markdown","metadata":{"id":"Gzc1rfQct7Kk"},"source":["# Scaling\n","<table >\n","  <tr>\n","    <th>Scaling Type</th>\n","    <th>What it does</th>\n","    <th>Scikit-Learn Function</th>\n","    <th>When to use</th>\n","  </tr>\n","  <tr>\n","    <td class=\"data\">Scale (normalization)</td>\n","    <td class=\"data\">Converts all values to between 0 and 1 whilst preserving the original distribution.</td>\n","    <td class=\"data\">MinMaxScaler</td>\n","    <td class=\"data\">Use as default scaler with neural networks.</td>\n","  </tr>\n","  <tr>\n","    <td>Standardization</td>\n","    <td>Removes the mean and divides each value by the standard deviation.</td>\n","    <td>StandardScaler</td>\n","    <td>Transform a feature to have close to normal distribution (caution: this reduces the effect of outliers).</td>\n","  </tr>\n","</table>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":142,"status":"ok","timestamp":1658343008612,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Wn1RKar8wRYn"},"outputs":[],"source":["from sklearn.compose import make_column_transformer\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","# Create a column transformer\n","ct = make_column_transformer(\n","    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]), # turn all values in these columns between 0 and 1\n","    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"]) # convert these text columns to one hot encoded\n",")\n","\n","# Create X & y\n","X = insurance.drop('charges', axis=1)\n","y = insurance['charges']\n","\n","# Build our train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Fit the column transformer to our training data\n","ct.fit(X_train)\n","\n","# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n","X_train_normal = ct.transform(X_train)\n","X_test_normal = ct.transform(X_test)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1658343012156,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"xYbh3UxT3PeL","outputId":"dde539d1-bb05-4794-f51f-920747e1f20b"},"outputs":[],"source":["# View data\n","X_train.loc[0], X_train_normal[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181,"status":"ok","timestamp":1658341740796,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"rPNiZKIl3n8D","outputId":"367bfef4-c37c-4f86-f500-de59832dba48"},"outputs":[],"source":["# Check shape\n","X_train.shape, X_train_normal.shape"]},{"cell_type":"markdown","metadata":{"id":"iumdm22j3vIJ"},"source":["Data has been normalized and one hot encoded.\n","Now let's build a neural network model on it."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11389,"status":"ok","timestamp":1658343558465,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"J4QPL7N0363h"},"outputs":[],"source":["# Build a neural network model to fit on our normalized data\n","tf.random.set_seed(42)\n","# Instantiate the model\n","normalized_model = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(100),\n","     tf.keras.layers.Dense(10),\n","     tf.keras.layers.Dense(1),\n","    ]\n",")\n","\n","# Compile the model\n","normalized_model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n","\n","# Fit the model\n","normalized_history = normalized_model.fit(X_train_normal, y_train, epochs=100, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11241,"status":"ok","timestamp":1658343610872,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"Jw4FEg8a6i_N"},"outputs":[],"source":["# Compare it to unprocesses data\n","# Create X and y values (features and labels)\n","X_unprocessed = insurance_one_hot.drop(\"charges\", axis=1)\n","y_unprocessed = insurance_one_hot[\"charges\"]\n","# Split unprocessed datasets\n","X_train_unprocessed, X_test_unprocessed, y_train_unprocessed, y_test_unprocessed = train_test_split(X_unprocessed, y_unprocessed, test_size=0.2, random_state=42)\n","tf.random.set_seed(42)\n","# Instantiate Model\n","unprocessed_model = tf.keras.Sequential(\n","    [\n","     tf.keras.layers.Dense(100),\n","     tf.keras.layers.Dense(10),\n","     tf.keras.layers.Dense(1)\n","    ]\n",")\n","# Compile\n","unprocessed_model.compile(loss=\"mae\", optimizer=\"adam\", metrics=[\"mae\"])\n","# Fit the model\n","unprocessed_history = unprocessed_model.fit(X_train_unprocessed, y_train_unprocessed, epochs=100, verbose=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":610,"status":"ok","timestamp":1658343612578,"user":{"displayName":"G C","userId":"16517429573012131229"},"user_tz":240},"id":"djltymG16wwr","outputId":"b94728be-35a7-4625-8a46-a01329cb9d24"},"outputs":[],"source":["# Evaluate the model\n","normalized_results = normalized_model.evaluate(X_test_normal, y_test)\n","unnormalized_results = unprocessed_model.evaluate(X_test_unprocessed, y_test_unprocessed)\n","print(normalized_results, '\\n\\n', unnormalized_results)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPJSH0pDxeWJUKoasdbZT5D","collapsed_sections":[],"mount_file_id":"1tl2T4_zSYE4E6N2GliUrGNrhzdfrz1M2","name":"02_neural_network_classification_in_tensorflow.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.9.12 64-bit ('miniconda3')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.12"},"vscode":{"interpreter":{"hash":"215bc93be91779c90c22d9452977b07e46a2652f59eedc500a409df416ed83eb"}}},"nbformat":4,"nbformat_minor":0}
